{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "WeeBit_CNN_LSTM_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m607stars/Reading-WeeBit-with-LSTMs-CNNs/blob/main/WeeBit_CNN_LSTM_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVC6j9XOC0J1"
      },
      "source": [
        "# Imports and Installs\n",
        "\n",
        "Note: DO NOT forget to change the path for saving models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upcb-2aDVp3I",
        "outputId": "8b3d1c5b-af6c-4e8b-ca6a-87ba5b0e17de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:20.192187Z",
          "iopub.execute_input": "2021-06-17T13:04:20.192588Z",
          "iopub.status.idle": "2021-06-17T13:04:20.196832Z",
          "shell.execute_reply.started": "2021-06-17T13:04:20.192493Z",
          "shell.execute_reply": "2021-06-17T13:04:20.195993Z"
        },
        "trusted": true,
        "id": "4DDm-bAEC0KA"
      },
      "source": [
        "# !pip install torchviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:31.917757Z",
          "iopub.execute_input": "2021-06-17T13:04:31.91814Z",
          "iopub.status.idle": "2021-06-17T13:04:34.255424Z",
          "shell.execute_reply.started": "2021-06-17T13:04:31.918108Z",
          "shell.execute_reply": "2021-06-17T13:04:34.25454Z"
        },
        "trusted": true,
        "id": "R7_VU3rsC0KD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext import vocab\n",
        "import random\n",
        "import nltk\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wCKUBIfaWyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980b3bba-5bad-4584-f8e1-6e0a698891bf"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJNC91OVSJow",
        "outputId": "82722394-1947-4f28-ea51-454318c1ca99"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    print(\"Seeding done\")\n",
        "seed_everything(42)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:34.257209Z",
          "iopub.execute_input": "2021-06-17T13:04:34.257534Z",
          "iopub.status.idle": "2021-06-17T13:05:23.83085Z",
          "shell.execute_reply.started": "2021-06-17T13:04:34.257499Z",
          "shell.execute_reply": "2021-06-17T13:05:23.829972Z"
        },
        "trusted": true,
        "id": "HVrapbC9C0KE"
      },
      "source": [
        "VECTOR_PATH = '/content/drive/MyDrive/Readability_Research_Paper/'\n",
        "VECTOR_NAME = 'glove.6B.300d.txt'\n",
        "\n",
        "TEXT_LENGTH = 187\n",
        "EMBEDDING_SIZE = 300\n",
        "HIDDEN_SIZE = 200\n",
        "BATCH_SIZE=16\n",
        "\n",
        "embeddings = vocab.Vectors(VECTOR_NAME,VECTOR_PATH)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:23.832382Z",
          "iopub.execute_input": "2021-06-17T13:05:23.832712Z",
          "iopub.status.idle": "2021-06-17T13:05:23.913894Z",
          "shell.execute_reply.started": "2021-06-17T13:05:23.832671Z",
          "shell.execute_reply": "2021-06-17T13:05:23.912978Z"
        },
        "trusted": true,
        "id": "n-hproQLC0KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f885ae45-e0b6-4246-b700-96f4180eab80"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print(device)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:23.915185Z",
          "iopub.execute_input": "2021-06-17T13:05:23.915509Z",
          "iopub.status.idle": "2021-06-17T13:05:24.025958Z",
          "shell.execute_reply.started": "2021-06-17T13:05:23.915472Z",
          "shell.execute_reply": "2021-06-17T13:05:24.025147Z"
        },
        "trusted": true,
        "id": "6f-ITJlLC0KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9b46136f-7356-4905-bb76-abda3d3bc11d"
      },
      "source": [
        "train_dataset = pd.read_csv('/content/drive/MyDrive/Readability_Research_Paper/train.csv')\n",
        "train_dataset['readability'] = train_dataset['readability'].apply(lambda x: x-2)\n",
        "train_dataset.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they sent me a salwar kameezpeacockblueand ano...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the chart shows each planet and its number of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this revision bite will help you understand wh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what are powers and roots find out how they work</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the wright brothers flew the first airplane ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  readability\n",
              "0  they sent me a salwar kameezpeacockblueand ano...            4\n",
              "1  the chart shows each planet and its number of ...            0\n",
              "2  this revision bite will help you understand wh...            4\n",
              "3   what are powers and roots find out how they work            3\n",
              "4  the wright brothers flew the first airplane ne...            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:24.027208Z",
          "iopub.execute_input": "2021-06-17T13:05:24.027531Z",
          "iopub.status.idle": "2021-06-17T13:05:24.047821Z",
          "shell.execute_reply.started": "2021-06-17T13:05:24.027495Z",
          "shell.execute_reply": "2021-06-17T13:05:24.047052Z"
        },
        "trusted": true,
        "id": "jPeUbL3eC0KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "da6640fc-ec04-40a6-f056-e1a2d504744d"
      },
      "source": [
        "test_dataset = pd.read_csv('/content/drive/MyDrive/Readability_Research_Paper/test.csv')\n",
        "test_dataset['readability'] = test_dataset['readability'].apply(lambda x: x-2)\n",
        "test_dataset.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>to understand a work of art or a beautiful obj...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>perhaps the most important of these is the use...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>q what is a tornados favorite game a twister</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the final thing to remember is there are lots ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3d shapes have 3dimensions length width and de...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  readability\n",
              "0  to understand a work of art or a beautiful obj...            4\n",
              "1  perhaps the most important of these is the use...            4\n",
              "2       q what is a tornados favorite game a twister            0\n",
              "3  the final thing to remember is there are lots ...            4\n",
              "4  3d shapes have 3dimensions length width and de...            3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27-DvDgAC0KH"
      },
      "source": [
        "# Data pre-processing and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:25.130689Z",
          "iopub.execute_input": "2021-06-17T13:05:25.131097Z",
          "iopub.status.idle": "2021-06-17T13:05:25.236336Z",
          "shell.execute_reply.started": "2021-06-17T13:05:25.131052Z",
          "shell.execute_reply": "2021-06-17T13:05:25.235398Z"
        },
        "trusted": true,
        "id": "_JAJiGSIC0KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f27f06-225d-42de-8d40-b1891ee35e69"
      },
      "source": [
        "def get_word_to_index(texts):\n",
        "    word_to_index = {\n",
        "        '<PAD>':0,\n",
        "        '<START>':1,\n",
        "        '<END>':2,\n",
        "    }\n",
        "    ind = 3\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        for word in words:\n",
        "            if word not in word_to_index.keys():\n",
        "                word_to_index[word] = ind\n",
        "                ind += 1\n",
        "                \n",
        "    return word_to_index   \n",
        "\n",
        "word_to_index_dict = get_word_to_index(train_dataset['text'])\n",
        "VOCABULARY_SIZE = len(word_to_index_dict.keys())\n",
        "print(VOCABULARY_SIZE)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:06:02.472213Z",
          "iopub.execute_input": "2021-06-17T13:06:02.472542Z",
          "iopub.status.idle": "2021-06-17T13:06:02.49165Z",
          "shell.execute_reply.started": "2021-06-17T13:06:02.472511Z",
          "shell.execute_reply": "2021-06-17T13:06:02.49062Z"
        },
        "trusted": true,
        "id": "33P8dmcMC0KJ"
      },
      "source": [
        "def get_tensor_from_text(text):\n",
        "    word_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        word_list.append(word_to_index_dict[word])\n",
        "    if len(word_list) > TEXT_LENGTH:\n",
        "        word_list = word_list[:TEXT_LENGTH]\n",
        "    else:\n",
        "        word_list.extend([0]*(TEXT_LENGTH-len(word_list)))\n",
        "    \n",
        "    tensor_list = torch.tensor(word_list, device=device, dtype=torch.long)\n",
        "    return tensor_list"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:06:04.311629Z",
          "iopub.execute_input": "2021-06-17T13:06:04.311985Z",
          "iopub.status.idle": "2021-06-17T13:06:04.317795Z",
          "shell.execute_reply.started": "2021-06-17T13:06:04.311954Z",
          "shell.execute_reply": "2021-06-17T13:06:04.31686Z"
        },
        "trusted": true,
        "id": "kL2XMh6hC0KK"
      },
      "source": [
        "class WeebitDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,dataset):\n",
        "        self.dataset = dataset\n",
        "    \n",
        "    def __getitem__(self,index): \n",
        "        text = self.dataset['text'].iloc[index]\n",
        "        y = torch.tensor(self.dataset['readability'].iloc[index],dtype=torch.float,device=device)\n",
        "        x = get_tensor_from_text(text)\n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M_DsPplMbRI"
      },
      "source": [
        "def create_embedding_matrix(embeddings,vocabulary_size):  \n",
        "    embedding_matrix = np.random.rand(vocabulary_size,EMBEDDING_SIZE)\n",
        "    for string,index in word_to_index_dict.items():\n",
        "        if not  all(x == 0 for x in embeddings[string].tolist()):\n",
        "            embedding_matrix[index] = embeddings[string] \n",
        "    return embedding_matrix"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q25Fe9HYumo"
      },
      "source": [
        "embedding_matrix = create_embedding_matrix(embeddings,VOCABULARY_SIZE)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcEGq9VHC0KL"
      },
      "source": [
        "# Model and Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2mjxZHn8JF6"
      },
      "source": [
        "## Done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktrWzCQLHjjV"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(x)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        output = linear_output_2\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T08:42:03.11576Z",
          "iopub.status.idle": "2021-06-17T08:42:03.116141Z"
        },
        "trusted": true,
        "id": "O-EhfRx3C0KL"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_1_CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output = conv_output_1.permute(0,2,1)  #shape of conv_output_2 is 16,61,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(conv_output)\n",
        "        #Shape of lstm_output_1 is 16,300,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        output = linear_output_4\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDsoeBUpkPyM"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_2_CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,300,61\n",
        "        conv_output = conv_output_1.permute(0,2,1)  #shape of conv_output_2 is 16,61,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(conv_output)\n",
        "        #Shape of lstm_output_1 is 16,300,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        output = linear_output_4\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpJpUULo8Uzj"
      },
      "source": [
        "## Current"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY3FXy3RmTkL"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_3_CNNs(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=7,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(185,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(61,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(21,128)\n",
        "\n",
        "        self.linear_layer_1 = torch.nn.Linear(900,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_4 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output_2 = self.conv_layer_2(x) #shape of conv_output_2 is 16,300,61\n",
        "        conv_output_3 = self.conv_layer_3(x) #shape of conv_output_3 is 16,300,21\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,300,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,300,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,300,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,900,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,900\n",
        "\n",
        "        linear_output_1 = self.linear_layer_1(conv_output)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "\n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)\n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "\n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)\n",
        "        output = linear_output_6\n",
        "        return output"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fxt1r0eIKHB"
      },
      "source": [
        "## To be done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-06T13:45:54.561125Z",
          "iopub.execute_input": "2021-06-06T13:45:54.561523Z",
          "iopub.status.idle": "2021-06-06T13:45:54.576383Z",
          "shell.execute_reply.started": "2021-06-06T13:45:54.561489Z",
          "shell.execute_reply": "2021-06-06T13:45:54.574846Z"
        },
        "trusted": true,
        "id": "f2l13b1hC0KN"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()       \n",
        "        self.output_layer = torch.nn.Linear(50,5)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUEILot8TH1"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.output_layer = torch.nn.Linear(187,5)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,187,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_M-nxJEC0KO"
      },
      "source": [
        "# Talha\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=200,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)       \n",
        "        self.output_layer = torch.nn.Linear(50,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-06T11:18:35.92226Z",
          "iopub.execute_input": "2021-06-06T11:18:35.925335Z",
          "iopub.status.idle": "2021-06-06T11:18:35.964619Z",
          "shell.execute_reply.started": "2021-06-06T11:18:35.925277Z",
          "shell.execute_reply": "2021-06-06T11:18:35.96208Z"
        },
        "trusted": true,
        "id": "E4_gghJNC0KP"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=200,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_embedding_context = torch.nn.Linear(1024,512)\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(512, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(256,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_3 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_4 = torch.nn.Linear(8,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=0.1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_1 = self.dropout_layer(conv_output_1)\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        attention_context = self.dropout_layer(attention_context)\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "        final_context_words = word_context*lstm_output_1  #Shape is 16,50,512\n",
        "        lstm_output_2, (ht2, ct2) = self.lstm_layer_2(final_context_words)\n",
        "        #Shape of lstm_output_2 is 16,50,1024 \n",
        "        #Shape of ht2 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht2[-1])     #Shape is 16,128\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)   #Shape is 16,32\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)   #Shape is 16,8\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)   #Shape is 16,1\n",
        "        output = linear_output_4   #Shape of output is 16,1\n",
        "        return output\n",
        "    \n",
        "# Average Validation Loss:0.9133829620398682 \n",
        "# Lowest Validation Loss: 0.8187914316807785 at fold 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T15:39:47.24523Z",
          "iopub.execute_input": "2021-06-12T15:39:47.245841Z",
          "iopub.status.idle": "2021-06-12T15:39:47.264813Z",
          "shell.execute_reply.started": "2021-06-12T15:39:47.245786Z",
          "shell.execute_reply": "2021-06-12T15:39:47.264052Z"
        },
        "trusted": true,
        "id": "dfpZBqlSC0KQ"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer_1 = torch.nn.Linear(3072,1024)\n",
        "        self.conv_output_linear_layer_2 = torch.nn.Linear(1024,256)\n",
        "        self.conv_output_linear_layer_3 = torch.nn.Linear(256,32)\n",
        "        self.conv_output_linear_layer_4 = torch.nn.Linear(32,8)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.conv_output_linear_layer_5 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_1 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        final_context_words = final_context_words.permute(0,2,1)\n",
        "        conv_output_1 = self.conv_layer_1(final_context_words)       #Shape is 16,1024,198\n",
        "        conv_output_2 = self.conv_layer_2(final_context_words)       #Shape is 16,1024,66\n",
        "        conv_output_3 = self.conv_layer_3(final_context_words)       #Shape is 16,1024,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,1024,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,1024,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,1024,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,3072,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,3072\n",
        "        conv_linear_output_1 = self.conv_output_linear_layer_1(conv_output)  #Shape is 16,128,1024\n",
        "        conv_linear_output_2 = self.conv_output_linear_layer_2(conv_linear_output_1)#Shape is 16,128,256\n",
        "        conv_linear_output_2 = self.tanh(conv_linear_output_2)\n",
        "        conv_linear_output_3 = self.conv_output_linear_layer_3(conv_linear_output_2)\n",
        "        conv_linear_output_4 = self.conv_output_linear_layer_4(conv_linear_output_3)\n",
        "        conv_linear_output_4 = self.tanh(conv_linear_output_4)\n",
        "        conv_linear_output_5 = self.conv_output_linear_layer_5(conv_linear_output_4)\n",
        "        conv_linear_output_5 = conv_linear_output_5.squeeze(2)\n",
        "        linear_output_1 = self.linear_layer_1(conv_linear_output_5)  #Shape is 16,64\n",
        "        linear_output_1 = self.tanh(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,1\n",
        "        output = linear_output_2   #Shape of output is 16,1\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.6796757201937529\n",
        "# Lowest validation loss is 0.6500918945654444 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-09T03:23:10.046616Z",
          "iopub.execute_input": "2021-06-09T03:23:10.047071Z",
          "iopub.status.idle": "2021-06-09T03:23:10.081609Z",
          "shell.execute_reply.started": "2021-06-09T03:23:10.047033Z",
          "shell.execute_reply": "2021-06-09T03:23:10.080605Z"
        },
        "trusted": true,
        "id": "FhFL925rC0KS"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention_CNN_GRU(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer_1 = torch.nn.Linear(3072,1024)\n",
        "        self.conv_output_linear_layer_2 = torch.nn.Linear(1024,256)\n",
        "        self.gru_layer = torch.nn.GRU(256,hidden_size,num_layers=num_of_layers,batch_first=True,\n",
        "                                     dropout=self.dropout_prob)\n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        final_context_words = final_context_words.permute(0,2,1)\n",
        "        conv_output_1 = self.conv_layer_1(final_context_words)       #Shape is 16,1024,198\n",
        "        conv_output_2 = self.conv_layer_2(final_context_words)       #Shape is 16,1024,66\n",
        "        conv_output_3 = self.conv_layer_3(final_context_words)       #Shape is 16,1024,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,1024,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,1024,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,1024,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,3072,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,3072\n",
        "        conv_linear_output_1 = self.conv_output_linear_layer_1(conv_output)  #Shape is 16,128,1024\n",
        "        conv_linear_output_2 = self.conv_output_linear_layer_2(conv_linear_output_1)#Shape is 16,128,256\n",
        "        gru_output , ht = self.gru_layer(conv_linear_output_2)\n",
        "        #Shape of ht is 16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])  #Shape is 16,64\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,8\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,1\n",
        "        output = linear_output_3   #Shape of output is 16,1\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:1.0334918799897828\n",
        "# Lowest avalidation loss is 1.013418031971577 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-07T14:56:01.375534Z",
          "iopub.execute_input": "2021-06-07T14:56:01.376153Z",
          "iopub.status.idle": "2021-06-07T14:56:01.401621Z",
          "shell.execute_reply.started": "2021-06-07T14:56:01.376099Z",
          "shell.execute_reply": "2021-06-07T14:56:01.400629Z"
        },
        "trusted": true,
        "id": "AroKhpBlC0KT"
      },
      "source": [
        "# mayank\n",
        "\n",
        "class CommonLitCNNLSTMAttention_EnsembleModel(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "                \n",
        "        self.embedding_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embedding_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix,\n",
        "                                                                      dtype=torch.float32,\n",
        "                                                                      device=device))\n",
        "        self.embedding_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1],hidden_size,\n",
        "                                          batch_first = True,num_layers = self.num_layers,\n",
        "                                          bidirectional=True)        \n",
        "        self.attention_linear_layer = torch.nn.Linear(hidden_size,2*hidden_size)\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(4*hidden_size,hidden_size,\n",
        "                                          batch_first=True,num_layers = self.num_layers,\n",
        "                                          bidirectional=True)\n",
        "        \n",
        "        # Block 2\n",
        "        self.lstm_layer_3 = torch.nn.LSTM(embedding_matrix.shape[1],hidden_size,\n",
        "                                    batch_first = True,num_layers = self.num_layers,\n",
        "                                    bidirectional=True)        \n",
        "        self.conv1 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=3,stride=1)\n",
        "        self.conv2 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=5,stride=1)\n",
        "        self.conv3 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=7,stride=1)\n",
        "        self.low_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                batch_first = True,num_layers = self.num_layers,\n",
        "                                bidirectional=True)\n",
        "        self.med_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                batch_first = True,num_layers = self.num_layers,\n",
        "                                bidirectional=True)\n",
        "        self.high_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                 batch_first = True,num_layers = self.num_layers,\n",
        "                                 bidirectional=True)\n",
        "        self.lstm_features_concat_layer = torch.nn.Linear(3*hidden_size,hidden_size)\n",
        "\n",
        "        #Combining Block 1 and 2\n",
        "        self.output_linear_1 = torch.nn.Linear(2*hidden_size,hidden_size)\n",
        "        self.output_linear_2 = torch.nn.Linear(hidden_size,hidden_size // 2)\n",
        "        self.output_linear_3 = torch.nn.Linear(hidden_size// 2,1)\n",
        "    \n",
        "    \n",
        "    def forward(self,input_text):\n",
        "        self.embeddings = self.embedding_layer(input_text.long().to(device))\n",
        "        self.embeddings = self.embeddings.permute(0, 2, 1)   # convert to [batch, channels, time]\n",
        "        self.embeddings = torch.nn.functional.dropout2d(self.embeddings, 0.2, training=self.training)\n",
        "        self.embeddings = self.embeddings.permute(0, 2, 1)\n",
        "        \n",
        "        #Block 1\n",
        "        lstm_output_1,(hidden_state_1,cell_state) = self.lstm_layer_1(self.embeddings)\n",
        "        final_state_1 = hidden_state_1[-1,:,:]\n",
        "        attention_linear_output = self.attention_linear_layer(final_state_1)\n",
        "        attention_linear_output = attention_linear_output.unsqueeze(1)\n",
        "        attention_multiplied_context = lstm_output_1 * attention_linear_output\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_multiplied_context,dim=1)\n",
        "        global_context = softmax_attention * lstm_output_1\n",
        "        final_context_words = torch.cat([global_context,lstm_output_1],dim=2) # 64,seq_len,4*hidden_size\n",
        "        lstm_output_2, (hidden_state_2,cell_state_2) = self.lstm_layer_2(final_context_words)\n",
        "        final_state_2 = hidden_state_2[-1,:,:]\n",
        "\n",
        "        #Block 2\n",
        "        lstm_output_3,(hidden_state_3,cell_state_3) = self.lstm_layer_3(self.embeddings)\n",
        "        lstm_output_3 = lstm_output_3.permute(0,2,1)\n",
        "        \n",
        "        conv_1_output = self.conv1(lstm_output_3)\n",
        "        conv_1_output = conv_1_output.permute(0,2,1) \n",
        "\n",
        "        conv_2_output = self.conv2(lstm_output_3)\n",
        "        conv_2_output = conv_2_output.permute(0,2,1)\n",
        "        \n",
        "        conv_3_output = self.conv3(lstm_output_3)\n",
        "        conv_3_output = conv_3_output.permute(0,2,1)\n",
        "\n",
        "        low_lstm_output,(hidden_state_low,cell_state_low) = self.low_lstm(conv_1_output)\n",
        "        med_lstm_output,(hidden_state_med,cell_state_med) = self.med_lstm(conv_2_output)\n",
        "        high_lstm_output,(hidden_state_high,cell_state_high) = self.high_lstm(conv_3_output)\n",
        "        concat_features = torch.cat([hidden_state_low[-1,:,:],hidden_state_med[-1,:,:],hidden_state_high[-1,:,:]],dim=1)\n",
        "        lstm_linear_concat_output = self.lstm_features_concat_layer(concat_features)\n",
        "\n",
        "        #Combining BLock 1 and 2 \n",
        "        short_long_context_features = torch.cat([final_state_2,lstm_linear_concat_output],dim=1)\n",
        "        linear_output_1 = self.output_linear_1(short_long_context_features)\n",
        "        linear_output_2 = self.output_linear_2(linear_output_1)\n",
        "        linear_output_3 = self.output_linear_3(linear_output_2)\n",
        "\n",
        "        return linear_output_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T10:16:38.008865Z",
          "iopub.execute_input": "2021-06-17T10:16:38.009177Z",
          "iopub.status.idle": "2021-06-17T10:16:38.03138Z",
          "shell.execute_reply.started": "2021-06-17T10:16:38.009147Z",
          "shell.execute_reply": "2021-06-17T10:16:38.03056Z"
        },
        "trusted": true,
        "id": "FzjZtmZvC0KU"
      },
      "source": [
        "# mayank\n",
        "\n",
        "class ReadabilityModel_parallel_LSTM_Attention_and_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.lstm_linear_layer = torch.nn.Linear(1024,256)\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer = torch.nn.Linear(900,256)\n",
        "        \n",
        "        # Combining both the blocks \n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_4 = torch.nn.Linear(328,128)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_7 = torch.nn.Linear(8,1)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_prob)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        block_1_output = self.lstm_linear_layer(final_context_words)  #Shape is 16,200,256\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        x_permuted = x.permute(0,2,1)   #Shape is 16,300,200\n",
        "        conv_output_1 = self.conv_layer_1(x_permuted)       #Shape is 16,300,198\n",
        "        conv_output_2 = self.conv_layer_2(x_permuted)       #Shape is 16,300,66\n",
        "        conv_output_3 = self.conv_layer_3(x_permuted)       #Shape is 16,300,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,300,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,300,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,300,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,900,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,900\n",
        "        block_2_output = self.conv_output_linear_layer(conv_output)  #Shape is 16,128,256\n",
        "        \n",
        "        # Combining block 1 & 2\n",
        "        concatenated_output = torch.cat([block_1_output,block_2_output],dim=1)  #Shape is 16,328,256\n",
        "        linear_output_1 = self.linear_layer_1(concatenated_output)  #Shape is 16,328,64\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        \n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,328,8\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        \n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,328,1\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_3 = linear_output_3.squeeze(2)            #Shape is 16,328\n",
        "        \n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)  #Shape is 16,128\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        \n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)  #Shape is 16,32\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)        \n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "        \n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)  #Shape is 16,8\n",
        "        linear_output_6 = self.dropout_layer(linear_output_6)\n",
        "\n",
        "        linear_output_7 = self.linear_layer_7(linear_output_6)  #Shape is 16,1\n",
        "        output = linear_output_7\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:\n",
        "# Lowest validation loss is  at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:07:03.522849Z",
          "iopub.execute_input": "2021-06-17T13:07:03.523228Z",
          "iopub.status.idle": "2021-06-17T13:07:03.546108Z",
          "shell.execute_reply.started": "2021-06-17T13:07:03.523197Z",
          "shell.execute_reply": "2021-06-17T13:07:03.544794Z"
        },
        "trusted": true,
        "id": "PMCdF2WAC0KU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "7d9f3c34-275c-45a5-fa80-19749118e382"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_parallel_LSTM_Attention_and_LSTM_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.lstm_linear_layer = torch.nn.Linear(1024,256)\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer = torch.nn.Linear(1536,256)\n",
        "        \n",
        "        # Combining both the blocks \n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_4 = torch.nn.Linear(328,128)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_7 = torch.nn.Linear(8,1)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_prob)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        block_1_output = self.lstm_linear_layer(final_context_words)  #Shape is 16,200,256\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        lstm_output_2, (ht2, ct2) = self.lstm_layer_2(x)\n",
        "        #Shape of lstm_output_2 is 16,200,512 \n",
        "        #Shape of ht2 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht2[-1] is 16,256\n",
        "        lstm_output_2_permuted = lstm_output_2.permute(0,2,1)   #Shape is 16,512,200\n",
        "        conv_output_1 = self.conv_layer_1(lstm_output_2_permuted)       #Shape is 16,512,198\n",
        "        conv_output_2 = self.conv_layer_2(lstm_output_2_permuted)       #Shape is 16,512,66\n",
        "        conv_output_3 = self.conv_layer_3(lstm_output_2_permuted)       #Shape is 16,512,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,512,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,512,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,512,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,1536,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,1536\n",
        "        block_2_output = self.conv_output_linear_layer(conv_output)  #Shape is 16,128,256\n",
        "        \n",
        "        # Combining block 1 & 2\n",
        "        concatenated_output = torch.cat([block_1_output,block_2_output],dim=1)  #Shape is 16,328,256\n",
        "        linear_output_1 = self.linear_layer_1(concatenated_output)  #Shape is 16,328,64\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        \n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,328,8\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        \n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,328,1\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_3 = linear_output_3.squeeze(2)            #Shape is 16,328\n",
        "        \n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)  #Shape is 16,128\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        \n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)  #Shape is 16,32\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)        \n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "        \n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)  #Shape is 16,8\n",
        "        linear_output_6 = self.dropout_layer(linear_output_6)\n",
        "\n",
        "        linear_output_7 = self.linear_layer_7(linear_output_6)  #Shape is 16,1\n",
        "        output = linear_output_7\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:\n",
        "# Lowest validation loss is  at fold 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c0e916e9ab83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mReadabilityModel_parallel_LSTM_Attention_and_LSTM_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ci_ao8XIVWM"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:07:07.025597Z",
          "iopub.execute_input": "2021-06-17T13:07:07.025948Z",
          "iopub.status.idle": "2021-06-17T17:01:04.936288Z",
          "shell.execute_reply.started": "2021-06-17T13:07:07.025916Z",
          "shell.execute_reply": "2021-06-17T17:01:04.935397Z"
        },
        "trusted": true,
        "id": "H6frPLDYC0KU"
      },
      "source": [
        "def train(train_dataset,valid_dataset,epochs,learning_rate,train_batch_size,valid_batch_size,embedding_matrix,hidden_size, num_of_layers):\n",
        "  loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size,\n",
        "                                            drop_last=True)\n",
        "  validloader = torch.utils.data.DataLoader(valid_dataset,batch_size=valid_batch_size,\n",
        "                                            drop_last=True)\n",
        "\n",
        "  model = ReadabilityModel_3_CNNs(embedding_matrix,\n",
        "                                              hidden_size, num_of_layers)\n",
        "  model = model.to(device)\n",
        "  train_loss_list,valid_loss_list = [],[]\n",
        "  train_accuracy_list,valid_accuracy_list = [],[]\n",
        "  for epoch in range(0, epochs):\n",
        "      epoch_loss = 0.0\n",
        "      model.train()\n",
        "      train_correct = 0\n",
        "      # learning_rate = 0.001/(epoch+1)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          inputs, targets = data\n",
        "          optimizer.zero_grad()\n",
        "          targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "          outputs = model(inputs)\n",
        "          output_ids = torch.argmax(outputs, dim=1)\n",
        "\n",
        "          loss = loss_function(outputs, targets)\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "      train_accuracy = 100 * train_correct / len(train_dataset)\n",
        "      epoch_loss /= len(trainloader) / train_batch_size \n",
        "      train_loss_list.append(epoch_loss)\n",
        "      train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        validation_loss = 0.0\n",
        "        valid_correct = 0\n",
        "        for i, data in enumerate(validloader, 0):\n",
        "            model.eval()\n",
        "            inputs, targets = data\n",
        "            targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "            outputs = model(inputs)\n",
        "            output_ids = torch.argmax(outputs, dim=1)\n",
        "            # outputs = outputs.squeeze(1)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            validation_loss += loss.item()\n",
        "            valid_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "      valid_accuracy = 100 * valid_correct / len(valid_dataset)  \n",
        "      validation_loss /= len(validloader) / valid_batch_size \n",
        "      valid_loss_list.append(validation_loss)\n",
        "      valid_accuracy_list.append(valid_accuracy)\n",
        "      print(f'Epoch:{epoch}, Training Loss:{epoch_loss} Validation Loss: {validation_loss} \\n Training accuracy:{train_accuracy} Validation Accuracy: {valid_accuracy} ')\n",
        "\n",
        "      torch.save(model,'/content/drive/MyDrive/Readability_Research_Paper/models/3_CNNs/lstm_{}.pkl'.format(epoch))    \n",
        "      print('--------------------------------')\n",
        "\n",
        "  return train_loss_list,valid_loss_list,train_accuracy_list,valid_accuracy_list,model"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvueADn3iPQg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_train_df, split_val_df = train_test_split(train_dataset,test_size=0.1,stratify=train_dataset['readability'])"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFBKon58cgZn"
      },
      "source": [
        "train_dataset_torch = WeebitDataset(split_train_df)\n",
        "valid_dataset_torch = WeebitDataset(split_val_df)\n",
        "EMBEDDING_SIZE = 300 \n",
        "hidden_size = 256\n",
        "num_of_layers = 3\n",
        "train_batch_size = 16\n",
        "valid_batch_size = 1\n",
        "epochs = 100\n",
        "learning_rate = 0.00005"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8b6YirPC0KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8670130-2c2b-4bc7-9b96-361df9722960"
      },
      "source": [
        "train_loss_list,valid_loss_list,train_accuracy_list,valid_accuracy_list,model = train(train_dataset_torch,valid_dataset_torch,epochs,learning_rate,\n",
        "                                                                                      train_batch_size,valid_batch_size,\n",
        "                                                                                      embedding_matrix,hidden_size,num_of_layers)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Training Loss:25.77796904700143 Validation Loss: 1.5994696402549744 \n",
            " Training accuracy:20.711111068725586 Validation Accuracy: 30.000001907348633 \n",
            "--------------------------------\n",
            "Epoch:1, Training Loss:25.33525733947754 Validation Loss: 1.5642809221744538 \n",
            " Training accuracy:28.933334350585938 Validation Accuracy: 28.80000114440918 \n",
            "--------------------------------\n",
            "Epoch:2, Training Loss:24.882863140106203 Validation Loss: 1.5471799989938737 \n",
            " Training accuracy:29.244443893432617 Validation Accuracy: 30.000001907348633 \n",
            "--------------------------------\n",
            "Epoch:3, Training Loss:24.62762106486729 Validation Loss: 1.5379322408437728 \n",
            " Training accuracy:30.933334350585938 Validation Accuracy: 34.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:4, Training Loss:24.35983302252633 Validation Loss: 1.5322680181860924 \n",
            " Training accuracy:31.511112213134766 Validation Accuracy: 32.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:5, Training Loss:24.19668619973319 Validation Loss: 1.5276897789239883 \n",
            " Training accuracy:31.822221755981445 Validation Accuracy: 33.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:6, Training Loss:24.008044678824287 Validation Loss: 1.5188840779662132 \n",
            " Training accuracy:32.844444274902344 Validation Accuracy: 34.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:7, Training Loss:23.97889886583601 Validation Loss: 1.5143496327400208 \n",
            " Training accuracy:33.02222442626953 Validation Accuracy: 33.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:8, Training Loss:23.878722395215714 Validation Loss: 1.5100547080039979 \n",
            " Training accuracy:33.599998474121094 Validation Accuracy: 33.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:9, Training Loss:23.853694316319057 Validation Loss: 1.5053976269364358 \n",
            " Training accuracy:34.93333435058594 Validation Accuracy: 33.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:10, Training Loss:23.70298852920532 Validation Loss: 1.4990497524142266 \n",
            " Training accuracy:35.24444580078125 Validation Accuracy: 33.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:11, Training Loss:23.421180874960765 Validation Loss: 1.4908393479585647 \n",
            " Training accuracy:35.866668701171875 Validation Accuracy: 34.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:12, Training Loss:23.249910817827498 Validation Loss: 1.4737405878305436 \n",
            " Training accuracy:35.911109924316406 Validation Accuracy: 35.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:13, Training Loss:22.79570187159947 Validation Loss: 1.436768621236086 \n",
            " Training accuracy:38.66666793823242 Validation Accuracy: 37.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:14, Training Loss:22.083104842049735 Validation Loss: 1.3867490219771863 \n",
            " Training accuracy:41.511112213134766 Validation Accuracy: 41.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:15, Training Loss:21.666685962677 Validation Loss: 1.3435709531903266 \n",
            " Training accuracy:43.11111068725586 Validation Accuracy: 47.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:16, Training Loss:20.755832426888603 Validation Loss: 1.2833623458743095 \n",
            " Training accuracy:47.64444351196289 Validation Accuracy: 52.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:17, Training Loss:19.85364955493382 Validation Loss: 1.2257281064987182 \n",
            " Training accuracy:50.0 Validation Accuracy: 54.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:18, Training Loss:18.786243193490165 Validation Loss: 1.1613783673197031 \n",
            " Training accuracy:52.22222137451172 Validation Accuracy: 55.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:19, Training Loss:17.474266597202845 Validation Loss: 1.0884798638299107 \n",
            " Training accuracy:56.31111145019531 Validation Accuracy: 56.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:20, Training Loss:16.57183700970241 Validation Loss: 1.046271747354418 \n",
            " Training accuracy:57.866668701171875 Validation Accuracy: 57.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:21, Training Loss:15.963137429101126 Validation Loss: 1.006784797374159 \n",
            " Training accuracy:57.20000076293945 Validation Accuracy: 59.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:22, Training Loss:15.204034205845424 Validation Loss: 0.9850394143033773 \n",
            " Training accuracy:59.333335876464844 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:23, Training Loss:14.668407767159598 Validation Loss: 0.9613556662611663 \n",
            " Training accuracy:61.9555549621582 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:24, Training Loss:14.115255526133947 Validation Loss: 0.93950769257918 \n",
            " Training accuracy:62.488887786865234 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:25, Training Loss:13.661646105561937 Validation Loss: 0.9230265507958829 \n",
            " Training accuracy:64.84444427490234 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:26, Training Loss:13.42769066606249 Validation Loss: 0.9080199676561169 \n",
            " Training accuracy:63.333335876464844 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:27, Training Loss:13.153768849372863 Validation Loss: 0.9040341410683468 \n",
            " Training accuracy:64.97777557373047 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:28, Training Loss:12.770425309453692 Validation Loss: 0.9014713947314303 \n",
            " Training accuracy:65.55555725097656 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:29, Training Loss:12.69586101600102 Validation Loss: 0.8893206703682663 \n",
            " Training accuracy:65.9111099243164 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:30, Training Loss:12.057686414037432 Validation Loss: 0.886291680655384 \n",
            " Training accuracy:67.11111450195312 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:31, Training Loss:12.040202169758933 Validation Loss: 0.8827410995679383 \n",
            " Training accuracy:67.73333740234375 Validation Accuracy: 66.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:32, Training Loss:11.532784513064794 Validation Loss: 0.882152832445252 \n",
            " Training accuracy:68.80000305175781 Validation Accuracy: 67.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:33, Training Loss:11.074172026770455 Validation Loss: 0.873899129817175 \n",
            " Training accuracy:69.37777709960938 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:34, Training Loss:10.876333611352104 Validation Loss: 0.8841538980094483 \n",
            " Training accuracy:70.62222290039062 Validation Accuracy: 67.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:35, Training Loss:10.934274700709752 Validation Loss: 0.8866508746829787 \n",
            " Training accuracy:70.62222290039062 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:36, Training Loss:10.736908204214913 Validation Loss: 0.8710184184245445 \n",
            " Training accuracy:70.4888916015625 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:37, Training Loss:10.501593954222542 Validation Loss: 0.8880196789844594 \n",
            " Training accuracy:71.37777709960938 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:38, Training Loss:10.225091910362243 Validation Loss: 0.8826410772790214 \n",
            " Training accuracy:71.82221984863281 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:39, Training Loss:10.27969295978546 Validation Loss: 0.8859537409215954 \n",
            " Training accuracy:73.20000457763672 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:40, Training Loss:9.873996949195861 Validation Loss: 0.8772927132903761 \n",
            " Training accuracy:72.93333435058594 Validation Accuracy: 67.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:41, Training Loss:9.70235235095024 Validation Loss: 0.9190565968203018 \n",
            " Training accuracy:73.28888702392578 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:42, Training Loss:9.475561390604291 Validation Loss: 0.9435497646719054 \n",
            " Training accuracy:74.75555419921875 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:43, Training Loss:9.530020376614162 Validation Loss: 0.9006733669050482 \n",
            " Training accuracy:73.33333587646484 Validation Accuracy: 66.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:44, Training Loss:9.33472877911159 Validation Loss: 0.9184789493532526 \n",
            " Training accuracy:75.15555572509766 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:45, Training Loss:9.067109532015664 Validation Loss: 0.921309239823972 \n",
            " Training accuracy:75.95555877685547 Validation Accuracy: 66.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:46, Training Loss:9.148841781275612 Validation Loss: 0.9201023447635738 \n",
            " Training accuracy:75.73333740234375 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:47, Training Loss:8.922185615130834 Validation Loss: 0.9245886046454057 \n",
            " Training accuracy:76.35555267333984 Validation Accuracy: 66.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:48, Training Loss:8.600244958911624 Validation Loss: 0.9415344191868146 \n",
            " Training accuracy:77.95555877685547 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:49, Training Loss:8.464883877549852 Validation Loss: 0.9897681031925426 \n",
            " Training accuracy:77.46666717529297 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:50, Training Loss:8.3776928458895 Validation Loss: 0.966396886530388 \n",
            " Training accuracy:79.02222442626953 Validation Accuracy: 68.0 \n",
            "--------------------------------\n",
            "Epoch:51, Training Loss:8.286339739390781 Validation Loss: 1.0043822327172067 \n",
            " Training accuracy:78.97777557373047 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:52, Training Loss:8.179511296749116 Validation Loss: 1.0092353321257865 \n",
            " Training accuracy:78.13333129882812 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:53, Training Loss:7.340826923506601 Validation Loss: 0.992032097250676 \n",
            " Training accuracy:80.75555419921875 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:54, Training Loss:7.3975554142679485 Validation Loss: 0.9982548476329673 \n",
            " Training accuracy:80.97777557373047 Validation Accuracy: 67.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:55, Training Loss:7.380827508653913 Validation Loss: 1.0825133740501838 \n",
            " Training accuracy:80.66666412353516 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:56, Training Loss:7.382579809427261 Validation Loss: 1.0519107208554184 \n",
            " Training accuracy:80.75555419921875 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:57, Training Loss:7.025049129554204 Validation Loss: 1.0887499497609243 \n",
            " Training accuracy:81.20000457763672 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:58, Training Loss:7.218065129007612 Validation Loss: 1.0608806235909631 \n",
            " Training accuracy:81.15555572509766 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:59, Training Loss:6.978648577417646 Validation Loss: 1.0514712233074979 \n",
            " Training accuracy:82.35555267333984 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:60, Training Loss:6.755301071064813 Validation Loss: 1.0679844789970905 \n",
            " Training accuracy:82.0 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:61, Training Loss:6.605446300336292 Validation Loss: 1.0960350017600886 \n",
            " Training accuracy:82.31111145019531 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:62, Training Loss:6.692542089734759 Validation Loss: 1.1035849300949618 \n",
            " Training accuracy:82.75555419921875 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:63, Training Loss:6.5094198346138 Validation Loss: 1.13876843927325 \n",
            " Training accuracy:82.0 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:64, Training Loss:6.111584676163537 Validation Loss: 1.1334489917217143 \n",
            " Training accuracy:84.4000015258789 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:65, Training Loss:5.962082225084305 Validation Loss: 1.1860845495248145 \n",
            " Training accuracy:84.66666412353516 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:66, Training Loss:6.167867980258805 Validation Loss: 1.1469467611117758 \n",
            " Training accuracy:84.22222137451172 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:67, Training Loss:5.780491045543125 Validation Loss: 1.208653399515774 \n",
            " Training accuracy:85.11111450195312 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:68, Training Loss:5.810467634456498 Validation Loss: 1.2287349176180462 \n",
            " Training accuracy:84.80000305175781 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:69, Training Loss:5.766828255142484 Validation Loss: 1.3115297571795177 \n",
            " Training accuracy:85.02222442626953 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:70, Training Loss:5.16123522903238 Validation Loss: 1.2302677232352413 \n",
            " Training accuracy:86.0888900756836 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:71, Training Loss:5.531145733169147 Validation Loss: 1.2831200703405516 \n",
            " Training accuracy:86.0 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:72, Training Loss:5.279291055245059 Validation Loss: 1.2781944370609166 \n",
            " Training accuracy:86.35556030273438 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:73, Training Loss:5.190555444785526 Validation Loss: 1.3372880029504166 \n",
            " Training accuracy:86.62222290039062 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:74, Training Loss:5.326621937326022 Validation Loss: 1.3452625778916607 \n",
            " Training accuracy:85.64444732666016 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:75, Training Loss:4.935050321263926 Validation Loss: 1.3722196167051017 \n",
            " Training accuracy:87.06666564941406 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:76, Training Loss:4.8653879774468285 Validation Loss: 1.4105499336424887 \n",
            " Training accuracy:87.24444580078125 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:77, Training Loss:4.765067225056035 Validation Loss: 1.3738555406097037 \n",
            " Training accuracy:88.04444885253906 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:78, Training Loss:4.406115669437817 Validation Loss: 1.418882500372153 \n",
            " Training accuracy:88.4000015258789 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:79, Training Loss:4.745792918226549 Validation Loss: 1.4506034965143835 \n",
            " Training accuracy:88.4000015258789 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:80, Training Loss:4.257147806457111 Validation Loss: 1.4703453802548865 \n",
            " Training accuracy:88.84444427490234 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:81, Training Loss:4.3037022986582345 Validation Loss: 1.5335754777019983 \n",
            " Training accuracy:89.06666564941406 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:82, Training Loss:4.448728839627334 Validation Loss: 1.5680436229405228 \n",
            " Training accuracy:89.37777709960938 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:83, Training Loss:4.430092411381858 Validation Loss: 1.5427792993592548 \n",
            " Training accuracy:88.62222290039062 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:84, Training Loss:4.3668651885752165 Validation Loss: 1.627179068787104 \n",
            " Training accuracy:89.5111083984375 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:85, Training Loss:3.9040592344743863 Validation Loss: 1.6983734386794918 \n",
            " Training accuracy:89.82221984863281 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:86, Training Loss:4.120150731503964 Validation Loss: 1.6026884503671195 \n",
            " Training accuracy:89.86666870117188 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:87, Training Loss:3.8854495511523317 Validation Loss: 1.6424474493910306 \n",
            " Training accuracy:90.13333129882812 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:88, Training Loss:3.660274442178862 Validation Loss: 1.7181325350662486 \n",
            " Training accuracy:90.80000305175781 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:89, Training Loss:3.6644254683383872 Validation Loss: 1.7355792641238958 \n",
            " Training accuracy:90.80000305175781 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:90, Training Loss:3.3191591323486396 Validation Loss: 1.7712539398902942 \n",
            " Training accuracy:91.06666564941406 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:91, Training Loss:3.479170701652765 Validation Loss: 1.892476894738298 \n",
            " Training accuracy:91.73333740234375 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:92, Training Loss:3.343240491513695 Validation Loss: 1.7396940827855678 \n",
            " Training accuracy:92.31111145019531 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:93, Training Loss:3.3331873372729337 Validation Loss: 1.7500725109266018 \n",
            " Training accuracy:91.9111099243164 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:94, Training Loss:3.452951345220208 Validation Loss: 1.8235298641002273 \n",
            " Training accuracy:91.86666870117188 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:95, Training Loss:3.2252273653234753 Validation Loss: 1.7826092020027222 \n",
            " Training accuracy:91.82221984863281 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:96, Training Loss:3.039238299722118 Validation Loss: 1.9636832905851926 \n",
            " Training accuracy:92.5777816772461 Validation Accuracy: 61.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:97, Training Loss:2.920330148057214 Validation Loss: 1.9539938063079256 \n",
            " Training accuracy:92.66666412353516 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:98, Training Loss:2.9828637449336903 Validation Loss: 1.8735531136804549 \n",
            " Training accuracy:92.84444427490234 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:99, Training Loss:3.010412145086697 Validation Loss: 1.878011455767421 \n",
            " Training accuracy:92.62222290039062 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JC_nrAEPd0aQ",
        "outputId": "b73ea390-7efc-4bb9-ebf2-da48857e3dfc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_list,'r',valid_loss_list , 'b')\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"], loc =\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQcisxcEpaYB"
      },
      "source": [
        "def get_tensor_from_text_test(text,dataset):\n",
        "    word_list = []\n",
        "    train_word_to_index_dict = get_word_to_index(dataset['text'])\n",
        "    text = text.lower()\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word in train_word_to_index_dict.keys()]\n",
        "    for word in words:\n",
        "        word_list.append(train_word_to_index_dict[word])\n",
        "    if len(word_list) > TEXT_LENGTH:\n",
        "        word_list = word_list[:TEXT_LENGTH]\n",
        "    else:\n",
        "        word_list.extend([0]*(TEXT_LENGTH-len(word_list)))\n",
        "    \n",
        "    tensor_list = torch.tensor(word_list, device=device, dtype=torch.long)\n",
        "    return tensor_list\n",
        "\n",
        "class WeebitTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,test_dataset,train_dataset):\n",
        "        self.dataset = test_dataset\n",
        "        self.train_dataset = train_dataset \n",
        "    \n",
        "    def __getitem__(self,index): \n",
        "        text = self.dataset['text'].iloc[index]\n",
        "        x = get_tensor_from_text_test(text,self.train_dataset)\n",
        "        y = torch.tensor(self.dataset['readability'].iloc[index],dtype=torch.float,device=device)\n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def test(dataset):\n",
        "  testloader = torch.utils.data.DataLoader(\n",
        "                      dataset,\n",
        "                      batch_size=1)\n",
        "  with torch.no_grad():   \n",
        "    model = torch.load('/content/drive/MyDrive/Readability_Research_Paper/models/3_CNNs/lstm_34.pkl')\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    target_list = []\n",
        "    output_list = []\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "      inputs, targets = data\n",
        "      # print(targets.item())\n",
        "      target_list.append(targets.item())\n",
        "      targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "      outputs = model(inputs)\n",
        "      output_ids = torch.argmax(outputs, dim=1)\n",
        "      output_list.append(output_ids.item())\n",
        "      # outputs = outputs.squeeze(1)\n",
        "      test_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / len(dataset)\n",
        "    confusion_matrix_calc = confusion_matrix(target_list,output_list)\n",
        "    classification_report_calc = classification_report(target_list,output_list)\n",
        "    return test_accuracy, confusion_matrix_calc, classification_report_calc"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXngB7mm9G9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8853ce6-3aaa-4a0c-b07a-b3f00bbda200"
      },
      "source": [
        "weebit_test_dataset = WeebitTestDataset(test_dataset, train_dataset)\n",
        "accuracy, confusion_matrix_calc, classification_report_calc = test(weebit_test_dataset)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIP5MhfG9XjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d91b43-7b3a-40e8-f040-239801fa2595"
      },
      "source": [
        "print(\"Testing accuracy is: \" + str(accuracy.item()))\n",
        "print(\"\\nConfusion Matrix\")\n",
        "print(confusion_matrix_calc)\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report_calc)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy is: 64.20000457763672\n",
            "\n",
            "Confusion Matrix\n",
            "[[59 28  8  5  0]\n",
            " [32 50 17  1  0]\n",
            " [12 36 49  2  1]\n",
            " [ 5  3  1 85  6]\n",
            " [ 4  0  1 17 78]]\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.59      0.56       100\n",
            "         1.0       0.43      0.50      0.46       100\n",
            "         2.0       0.64      0.49      0.56       100\n",
            "         3.0       0.77      0.85      0.81       100\n",
            "         4.0       0.92      0.78      0.84       100\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.66      0.64      0.65       500\n",
            "weighted avg       0.66      0.64      0.65       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtl34zWrN6Lz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}