{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "WeeBit_CNN_LSTM_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m607stars/Reading-WeeBit-with-LSTMs-CNNs/blob/main/WeeBit_CNN_LSTM_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVC6j9XOC0J1"
      },
      "source": [
        "# Imports and Installs\n",
        "\n",
        "Note: DO NOT forget to change the path for saving models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upcb-2aDVp3I",
        "outputId": "60b5c46e-8ff0-43ff-e2c6-bc6a8d50b6b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:20.192187Z",
          "iopub.execute_input": "2021-06-17T13:04:20.192588Z",
          "iopub.status.idle": "2021-06-17T13:04:20.196832Z",
          "shell.execute_reply.started": "2021-06-17T13:04:20.192493Z",
          "shell.execute_reply": "2021-06-17T13:04:20.195993Z"
        },
        "trusted": true,
        "id": "4DDm-bAEC0KA"
      },
      "source": [
        "# !pip install torchviz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:31.917757Z",
          "iopub.execute_input": "2021-06-17T13:04:31.91814Z",
          "iopub.status.idle": "2021-06-17T13:04:34.255424Z",
          "shell.execute_reply.started": "2021-06-17T13:04:31.918108Z",
          "shell.execute_reply": "2021-06-17T13:04:34.25454Z"
        },
        "trusted": true,
        "id": "R7_VU3rsC0KD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext import vocab\n",
        "import random\n",
        "import nltk\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wCKUBIfaWyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2a0400-d7b5-4500-a48b-22f0b1b32fee"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJNC91OVSJow",
        "outputId": "06f31ad1-14b8-4300-ee3e-d9e846156ef3"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    print(\"Seeding done\")\n",
        "seed_everything(42)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:34.257209Z",
          "iopub.execute_input": "2021-06-17T13:04:34.257534Z",
          "iopub.status.idle": "2021-06-17T13:05:23.83085Z",
          "shell.execute_reply.started": "2021-06-17T13:04:34.257499Z",
          "shell.execute_reply": "2021-06-17T13:05:23.829972Z"
        },
        "trusted": true,
        "id": "HVrapbC9C0KE"
      },
      "source": [
        "VECTOR_PATH = '/content/drive/MyDrive/Readability_Research_Paper/'\n",
        "VECTOR_NAME = 'glove.6B.300d.txt'\n",
        "\n",
        "TEXT_LENGTH = 187\n",
        "EMBEDDING_SIZE = 300\n",
        "HIDDEN_SIZE = 200\n",
        "BATCH_SIZE=16\n",
        "\n",
        "embeddings = vocab.Vectors(VECTOR_NAME,VECTOR_PATH)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:23.832382Z",
          "iopub.execute_input": "2021-06-17T13:05:23.832712Z",
          "iopub.status.idle": "2021-06-17T13:05:23.913894Z",
          "shell.execute_reply.started": "2021-06-17T13:05:23.832671Z",
          "shell.execute_reply": "2021-06-17T13:05:23.912978Z"
        },
        "trusted": true,
        "id": "n-hproQLC0KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9d473f-bc2a-4893-b443-01df4b577aba"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:23.915185Z",
          "iopub.execute_input": "2021-06-17T13:05:23.915509Z",
          "iopub.status.idle": "2021-06-17T13:05:24.025958Z",
          "shell.execute_reply.started": "2021-06-17T13:05:23.915472Z",
          "shell.execute_reply": "2021-06-17T13:05:24.025147Z"
        },
        "trusted": true,
        "id": "6f-ITJlLC0KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "45e0dfd8-706b-4fd9-b30c-0097bd495cb2"
      },
      "source": [
        "train_dataset = pd.read_csv('/content/drive/MyDrive/Readability_Research_Paper/train.csv')\n",
        "train_dataset['readability'] = train_dataset['readability'].apply(lambda x: x-2)\n",
        "train_dataset.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they sent me a salwar kameezpeacockblueand ano...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the chart shows each planet and its number of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this revision bite will help you understand wh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what are powers and roots find out how they work</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the wright brothers flew the first airplane ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  readability\n",
              "0  they sent me a salwar kameezpeacockblueand ano...            4\n",
              "1  the chart shows each planet and its number of ...            0\n",
              "2  this revision bite will help you understand wh...            4\n",
              "3   what are powers and roots find out how they work            3\n",
              "4  the wright brothers flew the first airplane ne...            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:24.027208Z",
          "iopub.execute_input": "2021-06-17T13:05:24.027531Z",
          "iopub.status.idle": "2021-06-17T13:05:24.047821Z",
          "shell.execute_reply.started": "2021-06-17T13:05:24.027495Z",
          "shell.execute_reply": "2021-06-17T13:05:24.047052Z"
        },
        "trusted": true,
        "id": "jPeUbL3eC0KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c41af70c-d19c-4b9e-af94-201ec82c7d79"
      },
      "source": [
        "test_dataset = pd.read_csv('/content/drive/MyDrive/Readability_Research_Paper/test.csv')\n",
        "test_dataset['readability'] = test_dataset['readability'].apply(lambda x: x-2)\n",
        "test_dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>to understand a work of art or a beautiful obj...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>perhaps the most important of these is the use...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>q what is a tornados favorite game a twister</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the final thing to remember is there are lots ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3d shapes have 3dimensions length width and de...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  readability\n",
              "0  to understand a work of art or a beautiful obj...            4\n",
              "1  perhaps the most important of these is the use...            4\n",
              "2       q what is a tornados favorite game a twister            0\n",
              "3  the final thing to remember is there are lots ...            4\n",
              "4  3d shapes have 3dimensions length width and de...            3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27-DvDgAC0KH"
      },
      "source": [
        "# Data pre-processing and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:25.130689Z",
          "iopub.execute_input": "2021-06-17T13:05:25.131097Z",
          "iopub.status.idle": "2021-06-17T13:05:25.236336Z",
          "shell.execute_reply.started": "2021-06-17T13:05:25.131052Z",
          "shell.execute_reply": "2021-06-17T13:05:25.235398Z"
        },
        "trusted": true,
        "id": "_JAJiGSIC0KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6529d96-8c1f-43d6-a5d9-55086f5bf1a5"
      },
      "source": [
        "def get_word_to_index(texts):\n",
        "    word_to_index = {\n",
        "        '<PAD>':0,\n",
        "        '<START>':1,\n",
        "        '<END>':2,\n",
        "    }\n",
        "    ind = 3\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        for word in words:\n",
        "            if word not in word_to_index.keys():\n",
        "                word_to_index[word] = ind\n",
        "                ind += 1\n",
        "                \n",
        "    return word_to_index   \n",
        "\n",
        "word_to_index_dict = get_word_to_index(train_dataset['text'])\n",
        "VOCABULARY_SIZE = len(word_to_index_dict.keys())\n",
        "print(VOCABULARY_SIZE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:06:02.472213Z",
          "iopub.execute_input": "2021-06-17T13:06:02.472542Z",
          "iopub.status.idle": "2021-06-17T13:06:02.49165Z",
          "shell.execute_reply.started": "2021-06-17T13:06:02.472511Z",
          "shell.execute_reply": "2021-06-17T13:06:02.49062Z"
        },
        "trusted": true,
        "id": "33P8dmcMC0KJ"
      },
      "source": [
        "def get_tensor_from_text(text):\n",
        "    word_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        word_list.append(word_to_index_dict[word])\n",
        "    if len(word_list) > TEXT_LENGTH:\n",
        "        word_list = word_list[:TEXT_LENGTH]\n",
        "    else:\n",
        "        word_list.extend([0]*(TEXT_LENGTH-len(word_list)))\n",
        "    \n",
        "    tensor_list = torch.tensor(word_list, device=device, dtype=torch.long)\n",
        "    return tensor_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:06:04.311629Z",
          "iopub.execute_input": "2021-06-17T13:06:04.311985Z",
          "iopub.status.idle": "2021-06-17T13:06:04.317795Z",
          "shell.execute_reply.started": "2021-06-17T13:06:04.311954Z",
          "shell.execute_reply": "2021-06-17T13:06:04.31686Z"
        },
        "trusted": true,
        "id": "kL2XMh6hC0KK"
      },
      "source": [
        "class WeebitDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,dataset):\n",
        "        self.dataset = dataset\n",
        "    \n",
        "    def __getitem__(self,index): \n",
        "        text = self.dataset['text'].iloc[index]\n",
        "        y = torch.tensor(self.dataset['readability'].iloc[index],dtype=torch.float,device=device)\n",
        "        x = get_tensor_from_text(text)\n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M_DsPplMbRI"
      },
      "source": [
        "def create_embedding_matrix(embeddings,vocabulary_size):  \n",
        "    embedding_matrix = np.random.rand(vocabulary_size,EMBEDDING_SIZE)\n",
        "    for string,index in word_to_index_dict.items():\n",
        "        if not  all(x == 0 for x in embeddings[string].tolist()):\n",
        "            embedding_matrix[index] = embeddings[string] \n",
        "    return embedding_matrix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q25Fe9HYumo"
      },
      "source": [
        "embedding_matrix = create_embedding_matrix(embeddings,VOCABULARY_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcEGq9VHC0KL"
      },
      "source": [
        "# Model and Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2mjxZHn8JF6"
      },
      "source": [
        "## Done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktrWzCQLHjjV"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(x)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        output = linear_output_2\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T08:42:03.11576Z",
          "iopub.status.idle": "2021-06-17T08:42:03.116141Z"
        },
        "trusted": true,
        "id": "O-EhfRx3C0KL"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_1_CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output = conv_output_1.permute(0,2,1)  #shape of conv_output_2 is 16,61,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(conv_output)\n",
        "        #Shape of lstm_output_1 is 16,300,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        output = linear_output_4\n",
        "        return output"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDsoeBUpkPyM"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_2_CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,300,61\n",
        "        conv_output = conv_output_1.permute(0,2,1)  #shape of conv_output_2 is 16,61,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(conv_output)\n",
        "        #Shape of lstm_output_1 is 16,300,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        output = linear_output_4\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-06T13:45:54.561125Z",
          "iopub.execute_input": "2021-06-06T13:45:54.561523Z",
          "iopub.status.idle": "2021-06-06T13:45:54.576383Z",
          "shell.execute_reply.started": "2021-06-06T13:45:54.561489Z",
          "shell.execute_reply": "2021-06-06T13:45:54.574846Z"
        },
        "trusted": true,
        "id": "f2l13b1hC0KN"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()       \n",
        "        self.output_layer = torch.nn.Linear(50,5)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpJpUULo8Uzj"
      },
      "source": [
        "## Current"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY3FXy3RmTkL"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_2_CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,300,61\n",
        "        conv_output = conv_output_1.permute(0,2,1)  #shape of conv_output_2 is 16,61,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(conv_output)\n",
        "        #Shape of lstm_output_1 is 16,300,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        output = linear_output_4\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fxt1r0eIKHB"
      },
      "source": [
        "## To be done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUEILot8TH1"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.output_layer = torch.nn.Linear(187,5)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,187,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_M-nxJEC0KO"
      },
      "source": [
        "# Talha\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=200,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)       \n",
        "        self.output_layer = torch.nn.Linear(50,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-06T11:18:35.92226Z",
          "iopub.execute_input": "2021-06-06T11:18:35.925335Z",
          "iopub.status.idle": "2021-06-06T11:18:35.964619Z",
          "shell.execute_reply.started": "2021-06-06T11:18:35.925277Z",
          "shell.execute_reply": "2021-06-06T11:18:35.96208Z"
        },
        "trusted": true,
        "id": "E4_gghJNC0KP"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=200,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_embedding_context = torch.nn.Linear(1024,512)\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(512, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(256,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_3 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_4 = torch.nn.Linear(8,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=0.1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_1 = self.dropout_layer(conv_output_1)\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        attention_context = self.dropout_layer(attention_context)\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "        final_context_words = word_context*lstm_output_1  #Shape is 16,50,512\n",
        "        lstm_output_2, (ht2, ct2) = self.lstm_layer_2(final_context_words)\n",
        "        #Shape of lstm_output_2 is 16,50,1024 \n",
        "        #Shape of ht2 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht2[-1])     #Shape is 16,128\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)   #Shape is 16,32\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)   #Shape is 16,8\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)   #Shape is 16,1\n",
        "        output = linear_output_4   #Shape of output is 16,1\n",
        "        return output\n",
        "    \n",
        "# Average Validation Loss:0.9133829620398682 \n",
        "# Lowest Validation Loss: 0.8187914316807785 at fold 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T15:39:47.24523Z",
          "iopub.execute_input": "2021-06-12T15:39:47.245841Z",
          "iopub.status.idle": "2021-06-12T15:39:47.264813Z",
          "shell.execute_reply.started": "2021-06-12T15:39:47.245786Z",
          "shell.execute_reply": "2021-06-12T15:39:47.264052Z"
        },
        "trusted": true,
        "id": "dfpZBqlSC0KQ"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer_1 = torch.nn.Linear(3072,1024)\n",
        "        self.conv_output_linear_layer_2 = torch.nn.Linear(1024,256)\n",
        "        self.conv_output_linear_layer_3 = torch.nn.Linear(256,32)\n",
        "        self.conv_output_linear_layer_4 = torch.nn.Linear(32,8)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.conv_output_linear_layer_5 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_1 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        final_context_words = final_context_words.permute(0,2,1)\n",
        "        conv_output_1 = self.conv_layer_1(final_context_words)       #Shape is 16,1024,198\n",
        "        conv_output_2 = self.conv_layer_2(final_context_words)       #Shape is 16,1024,66\n",
        "        conv_output_3 = self.conv_layer_3(final_context_words)       #Shape is 16,1024,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,1024,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,1024,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,1024,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,3072,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,3072\n",
        "        conv_linear_output_1 = self.conv_output_linear_layer_1(conv_output)  #Shape is 16,128,1024\n",
        "        conv_linear_output_2 = self.conv_output_linear_layer_2(conv_linear_output_1)#Shape is 16,128,256\n",
        "        conv_linear_output_2 = self.tanh(conv_linear_output_2)\n",
        "        conv_linear_output_3 = self.conv_output_linear_layer_3(conv_linear_output_2)\n",
        "        conv_linear_output_4 = self.conv_output_linear_layer_4(conv_linear_output_3)\n",
        "        conv_linear_output_4 = self.tanh(conv_linear_output_4)\n",
        "        conv_linear_output_5 = self.conv_output_linear_layer_5(conv_linear_output_4)\n",
        "        conv_linear_output_5 = conv_linear_output_5.squeeze(2)\n",
        "        linear_output_1 = self.linear_layer_1(conv_linear_output_5)  #Shape is 16,64\n",
        "        linear_output_1 = self.tanh(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,1\n",
        "        output = linear_output_2   #Shape of output is 16,1\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.6796757201937529\n",
        "# Lowest validation loss is 0.6500918945654444 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-09T03:23:10.046616Z",
          "iopub.execute_input": "2021-06-09T03:23:10.047071Z",
          "iopub.status.idle": "2021-06-09T03:23:10.081609Z",
          "shell.execute_reply.started": "2021-06-09T03:23:10.047033Z",
          "shell.execute_reply": "2021-06-09T03:23:10.080605Z"
        },
        "trusted": true,
        "id": "FhFL925rC0KS"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention_CNN_GRU(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer_1 = torch.nn.Linear(3072,1024)\n",
        "        self.conv_output_linear_layer_2 = torch.nn.Linear(1024,256)\n",
        "        self.gru_layer = torch.nn.GRU(256,hidden_size,num_layers=num_of_layers,batch_first=True,\n",
        "                                     dropout=self.dropout_prob)\n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        final_context_words = final_context_words.permute(0,2,1)\n",
        "        conv_output_1 = self.conv_layer_1(final_context_words)       #Shape is 16,1024,198\n",
        "        conv_output_2 = self.conv_layer_2(final_context_words)       #Shape is 16,1024,66\n",
        "        conv_output_3 = self.conv_layer_3(final_context_words)       #Shape is 16,1024,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,1024,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,1024,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,1024,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,3072,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,3072\n",
        "        conv_linear_output_1 = self.conv_output_linear_layer_1(conv_output)  #Shape is 16,128,1024\n",
        "        conv_linear_output_2 = self.conv_output_linear_layer_2(conv_linear_output_1)#Shape is 16,128,256\n",
        "        gru_output , ht = self.gru_layer(conv_linear_output_2)\n",
        "        #Shape of ht is 16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])  #Shape is 16,64\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,8\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,1\n",
        "        output = linear_output_3   #Shape of output is 16,1\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:1.0334918799897828\n",
        "# Lowest avalidation loss is 1.013418031971577 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-07T14:56:01.375534Z",
          "iopub.execute_input": "2021-06-07T14:56:01.376153Z",
          "iopub.status.idle": "2021-06-07T14:56:01.401621Z",
          "shell.execute_reply.started": "2021-06-07T14:56:01.376099Z",
          "shell.execute_reply": "2021-06-07T14:56:01.400629Z"
        },
        "trusted": true,
        "id": "AroKhpBlC0KT"
      },
      "source": [
        "# mayank\n",
        "\n",
        "class CommonLitCNNLSTMAttention_EnsembleModel(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "                \n",
        "        self.embedding_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embedding_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix,\n",
        "                                                                      dtype=torch.float32,\n",
        "                                                                      device=device))\n",
        "        self.embedding_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1],hidden_size,\n",
        "                                          batch_first = True,num_layers = self.num_layers,\n",
        "                                          bidirectional=True)        \n",
        "        self.attention_linear_layer = torch.nn.Linear(hidden_size,2*hidden_size)\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(4*hidden_size,hidden_size,\n",
        "                                          batch_first=True,num_layers = self.num_layers,\n",
        "                                          bidirectional=True)\n",
        "        \n",
        "        # Block 2\n",
        "        self.lstm_layer_3 = torch.nn.LSTM(embedding_matrix.shape[1],hidden_size,\n",
        "                                    batch_first = True,num_layers = self.num_layers,\n",
        "                                    bidirectional=True)        \n",
        "        self.conv1 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=3,stride=1)\n",
        "        self.conv2 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=5,stride=1)\n",
        "        self.conv3 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=7,stride=1)\n",
        "        self.low_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                batch_first = True,num_layers = self.num_layers,\n",
        "                                bidirectional=True)\n",
        "        self.med_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                batch_first = True,num_layers = self.num_layers,\n",
        "                                bidirectional=True)\n",
        "        self.high_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                 batch_first = True,num_layers = self.num_layers,\n",
        "                                 bidirectional=True)\n",
        "        self.lstm_features_concat_layer = torch.nn.Linear(3*hidden_size,hidden_size)\n",
        "\n",
        "        #Combining Block 1 and 2\n",
        "        self.output_linear_1 = torch.nn.Linear(2*hidden_size,hidden_size)\n",
        "        self.output_linear_2 = torch.nn.Linear(hidden_size,hidden_size // 2)\n",
        "        self.output_linear_3 = torch.nn.Linear(hidden_size// 2,1)\n",
        "    \n",
        "    \n",
        "    def forward(self,input_text):\n",
        "        self.embeddings = self.embedding_layer(input_text.long().to(device))\n",
        "        self.embeddings = self.embeddings.permute(0, 2, 1)   # convert to [batch, channels, time]\n",
        "        self.embeddings = torch.nn.functional.dropout2d(self.embeddings, 0.2, training=self.training)\n",
        "        self.embeddings = self.embeddings.permute(0, 2, 1)\n",
        "        \n",
        "        #Block 1\n",
        "        lstm_output_1,(hidden_state_1,cell_state) = self.lstm_layer_1(self.embeddings)\n",
        "        final_state_1 = hidden_state_1[-1,:,:]\n",
        "        attention_linear_output = self.attention_linear_layer(final_state_1)\n",
        "        attention_linear_output = attention_linear_output.unsqueeze(1)\n",
        "        attention_multiplied_context = lstm_output_1 * attention_linear_output\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_multiplied_context,dim=1)\n",
        "        global_context = softmax_attention * lstm_output_1\n",
        "        final_context_words = torch.cat([global_context,lstm_output_1],dim=2) # 64,seq_len,4*hidden_size\n",
        "        lstm_output_2, (hidden_state_2,cell_state_2) = self.lstm_layer_2(final_context_words)\n",
        "        final_state_2 = hidden_state_2[-1,:,:]\n",
        "\n",
        "        #Block 2\n",
        "        lstm_output_3,(hidden_state_3,cell_state_3) = self.lstm_layer_3(self.embeddings)\n",
        "        lstm_output_3 = lstm_output_3.permute(0,2,1)\n",
        "        \n",
        "        conv_1_output = self.conv1(lstm_output_3)\n",
        "        conv_1_output = conv_1_output.permute(0,2,1) \n",
        "\n",
        "        conv_2_output = self.conv2(lstm_output_3)\n",
        "        conv_2_output = conv_2_output.permute(0,2,1)\n",
        "        \n",
        "        conv_3_output = self.conv3(lstm_output_3)\n",
        "        conv_3_output = conv_3_output.permute(0,2,1)\n",
        "\n",
        "        low_lstm_output,(hidden_state_low,cell_state_low) = self.low_lstm(conv_1_output)\n",
        "        med_lstm_output,(hidden_state_med,cell_state_med) = self.med_lstm(conv_2_output)\n",
        "        high_lstm_output,(hidden_state_high,cell_state_high) = self.high_lstm(conv_3_output)\n",
        "        concat_features = torch.cat([hidden_state_low[-1,:,:],hidden_state_med[-1,:,:],hidden_state_high[-1,:,:]],dim=1)\n",
        "        lstm_linear_concat_output = self.lstm_features_concat_layer(concat_features)\n",
        "\n",
        "        #Combining BLock 1 and 2 \n",
        "        short_long_context_features = torch.cat([final_state_2,lstm_linear_concat_output],dim=1)\n",
        "        linear_output_1 = self.output_linear_1(short_long_context_features)\n",
        "        linear_output_2 = self.output_linear_2(linear_output_1)\n",
        "        linear_output_3 = self.output_linear_3(linear_output_2)\n",
        "\n",
        "        return linear_output_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T10:16:38.008865Z",
          "iopub.execute_input": "2021-06-17T10:16:38.009177Z",
          "iopub.status.idle": "2021-06-17T10:16:38.03138Z",
          "shell.execute_reply.started": "2021-06-17T10:16:38.009147Z",
          "shell.execute_reply": "2021-06-17T10:16:38.03056Z"
        },
        "trusted": true,
        "id": "FzjZtmZvC0KU"
      },
      "source": [
        "# mayank\n",
        "\n",
        "class ReadabilityModel_parallel_LSTM_Attention_and_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.lstm_linear_layer = torch.nn.Linear(1024,256)\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer = torch.nn.Linear(900,256)\n",
        "        \n",
        "        # Combining both the blocks \n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_4 = torch.nn.Linear(328,128)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_7 = torch.nn.Linear(8,1)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_prob)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        block_1_output = self.lstm_linear_layer(final_context_words)  #Shape is 16,200,256\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        x_permuted = x.permute(0,2,1)   #Shape is 16,300,200\n",
        "        conv_output_1 = self.conv_layer_1(x_permuted)       #Shape is 16,300,198\n",
        "        conv_output_2 = self.conv_layer_2(x_permuted)       #Shape is 16,300,66\n",
        "        conv_output_3 = self.conv_layer_3(x_permuted)       #Shape is 16,300,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,300,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,300,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,300,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,900,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,900\n",
        "        block_2_output = self.conv_output_linear_layer(conv_output)  #Shape is 16,128,256\n",
        "        \n",
        "        # Combining block 1 & 2\n",
        "        concatenated_output = torch.cat([block_1_output,block_2_output],dim=1)  #Shape is 16,328,256\n",
        "        linear_output_1 = self.linear_layer_1(concatenated_output)  #Shape is 16,328,64\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        \n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,328,8\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        \n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,328,1\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_3 = linear_output_3.squeeze(2)            #Shape is 16,328\n",
        "        \n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)  #Shape is 16,128\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        \n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)  #Shape is 16,32\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)        \n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "        \n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)  #Shape is 16,8\n",
        "        linear_output_6 = self.dropout_layer(linear_output_6)\n",
        "\n",
        "        linear_output_7 = self.linear_layer_7(linear_output_6)  #Shape is 16,1\n",
        "        output = linear_output_7\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:\n",
        "# Lowest validation loss is  at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:07:03.522849Z",
          "iopub.execute_input": "2021-06-17T13:07:03.523228Z",
          "iopub.status.idle": "2021-06-17T13:07:03.546108Z",
          "shell.execute_reply.started": "2021-06-17T13:07:03.523197Z",
          "shell.execute_reply": "2021-06-17T13:07:03.544794Z"
        },
        "trusted": true,
        "id": "PMCdF2WAC0KU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "7d9f3c34-275c-45a5-fa80-19749118e382"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_parallel_LSTM_Attention_and_LSTM_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.lstm_linear_layer = torch.nn.Linear(1024,256)\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer = torch.nn.Linear(1536,256)\n",
        "        \n",
        "        # Combining both the blocks \n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_4 = torch.nn.Linear(328,128)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_7 = torch.nn.Linear(8,1)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_prob)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        block_1_output = self.lstm_linear_layer(final_context_words)  #Shape is 16,200,256\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        lstm_output_2, (ht2, ct2) = self.lstm_layer_2(x)\n",
        "        #Shape of lstm_output_2 is 16,200,512 \n",
        "        #Shape of ht2 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht2[-1] is 16,256\n",
        "        lstm_output_2_permuted = lstm_output_2.permute(0,2,1)   #Shape is 16,512,200\n",
        "        conv_output_1 = self.conv_layer_1(lstm_output_2_permuted)       #Shape is 16,512,198\n",
        "        conv_output_2 = self.conv_layer_2(lstm_output_2_permuted)       #Shape is 16,512,66\n",
        "        conv_output_3 = self.conv_layer_3(lstm_output_2_permuted)       #Shape is 16,512,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,512,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,512,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,512,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,1536,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,1536\n",
        "        block_2_output = self.conv_output_linear_layer(conv_output)  #Shape is 16,128,256\n",
        "        \n",
        "        # Combining block 1 & 2\n",
        "        concatenated_output = torch.cat([block_1_output,block_2_output],dim=1)  #Shape is 16,328,256\n",
        "        linear_output_1 = self.linear_layer_1(concatenated_output)  #Shape is 16,328,64\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        \n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,328,8\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        \n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,328,1\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_3 = linear_output_3.squeeze(2)            #Shape is 16,328\n",
        "        \n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)  #Shape is 16,128\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        \n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)  #Shape is 16,32\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)        \n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "        \n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)  #Shape is 16,8\n",
        "        linear_output_6 = self.dropout_layer(linear_output_6)\n",
        "\n",
        "        linear_output_7 = self.linear_layer_7(linear_output_6)  #Shape is 16,1\n",
        "        output = linear_output_7\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:\n",
        "# Lowest validation loss is  at fold 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c0e916e9ab83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mReadabilityModel_parallel_LSTM_Attention_and_LSTM_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ci_ao8XIVWM"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:07:07.025597Z",
          "iopub.execute_input": "2021-06-17T13:07:07.025948Z",
          "iopub.status.idle": "2021-06-17T17:01:04.936288Z",
          "shell.execute_reply.started": "2021-06-17T13:07:07.025916Z",
          "shell.execute_reply": "2021-06-17T17:01:04.935397Z"
        },
        "trusted": true,
        "id": "H6frPLDYC0KU"
      },
      "source": [
        "def train(train_dataset,valid_dataset,epochs,learning_rate,train_batch_size,valid_batch_size,embedding_matrix,hidden_size, num_of_layers):\n",
        "  loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size,\n",
        "                                            drop_last=True)\n",
        "  validloader = torch.utils.data.DataLoader(valid_dataset,batch_size=valid_batch_size,\n",
        "                                            drop_last=True)\n",
        "\n",
        "  model = ReadabilityModel_CNN_LSTM(embedding_matrix,\n",
        "                                              hidden_size, num_of_layers)\n",
        "  model = model.to(device)\n",
        "  train_loss_list,valid_loss_list = [],[]\n",
        "  train_accuracy_list,valid_accuracy_list = [],[]\n",
        "  for epoch in range(0, epochs):\n",
        "      epoch_loss = 0.0\n",
        "      model.train()\n",
        "      train_correct = 0\n",
        "      # learning_rate = 0.001/(epoch+1)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          inputs, targets = data\n",
        "          optimizer.zero_grad()\n",
        "          targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "          outputs = model(inputs)\n",
        "          output_ids = torch.argmax(outputs, dim=1)\n",
        "\n",
        "          loss = loss_function(outputs, targets)\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "      train_accuracy = 100 * train_correct / len(train_dataset)\n",
        "      epoch_loss /= len(trainloader) / train_batch_size \n",
        "      train_loss_list.append(epoch_loss)\n",
        "      train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        validation_loss = 0.0\n",
        "        valid_correct = 0\n",
        "        for i, data in enumerate(validloader, 0):\n",
        "            model.eval()\n",
        "            inputs, targets = data\n",
        "            targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "            outputs = model(inputs)\n",
        "            output_ids = torch.argmax(outputs, dim=1)\n",
        "            # outputs = outputs.squeeze(1)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            validation_loss += loss.item()\n",
        "            valid_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "      valid_accuracy = 100 * valid_correct / len(valid_dataset)  \n",
        "      validation_loss /= len(validloader) / valid_batch_size \n",
        "      valid_loss_list.append(validation_loss)\n",
        "      valid_accuracy_list.append(valid_accuracy)\n",
        "      print(f'Epoch:{epoch}, Training Loss:{epoch_loss} Validation Loss: {validation_loss} \\n Training accuracy:{train_accuracy} Validation Accuracy: {valid_accuracy} ')\n",
        "\n",
        "      torch.save(model,'/content/drive/MyDrive/Readability_Research_Paper/models/1-cnn_lstm/lstm_{}.pkl'.format(epoch))    \n",
        "      print('--------------------------------')\n",
        "\n",
        "  return train_loss_list,valid_loss_list,train_accuracy_list,valid_accuracy_list,model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvueADn3iPQg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_train_df, split_val_df = train_test_split(train_dataset,test_size=0.1,stratify=train_dataset['readability'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFBKon58cgZn"
      },
      "source": [
        "train_dataset_torch = WeebitDataset(split_train_df)\n",
        "valid_dataset_torch = WeebitDataset(split_val_df)\n",
        "EMBEDDING_SIZE = 300 \n",
        "hidden_size = 256\n",
        "num_of_layers = 3\n",
        "train_batch_size = 16\n",
        "valid_batch_size = 1\n",
        "epochs = 100\n",
        "learning_rate = 0.00005"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8b6YirPC0KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b14eb0-2360-46db-b44e-5d924a54fc15"
      },
      "source": [
        "train_loss_list,valid_loss_list,train_accuracy_list,valid_accuracy_list,model = train(train_dataset_torch,valid_dataset_torch,epochs,learning_rate,\n",
        "                                                                                      train_batch_size,valid_batch_size,\n",
        "                                                                                      embedding_matrix,hidden_size,num_of_layers)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Training Loss:25.7065076146807 Validation Loss: 1.558850932598114 \n",
            " Training accuracy:21.377777099609375 Validation Accuracy: 36.0 \n",
            "--------------------------------\n",
            "Epoch:1, Training Loss:23.89171176637922 Validation Loss: 1.4526666378974915 \n",
            " Training accuracy:32.75555419921875 Validation Accuracy: 34.0 \n",
            "--------------------------------\n",
            "Epoch:2, Training Loss:22.84425695964268 Validation Loss: 1.4458409550189972 \n",
            " Training accuracy:30.933334350585938 Validation Accuracy: 33.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:3, Training Loss:21.939047581808907 Validation Loss: 1.3242207107543946 \n",
            " Training accuracy:32.22222137451172 Validation Accuracy: 36.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:4, Training Loss:21.031936168670654 Validation Loss: 1.283834582567215 \n",
            " Training accuracy:35.46666717529297 Validation Accuracy: 36.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:5, Training Loss:20.412571334838866 Validation Loss: 1.249077508687973 \n",
            " Training accuracy:37.06666564941406 Validation Accuracy: 40.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:6, Training Loss:19.89522213254656 Validation Loss: 1.24425376868248 \n",
            " Training accuracy:36.4444465637207 Validation Accuracy: 38.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:7, Training Loss:18.98674646786281 Validation Loss: 1.1293963394165039 \n",
            " Training accuracy:37.64444351196289 Validation Accuracy: 42.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:8, Training Loss:18.394323205947877 Validation Loss: 1.0692235748767853 \n",
            " Training accuracy:38.844444274902344 Validation Accuracy: 42.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:9, Training Loss:18.01015885216849 Validation Loss: 1.0730096840858458 \n",
            " Training accuracy:38.13333511352539 Validation Accuracy: 43.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:10, Training Loss:17.82769226346697 Validation Loss: 1.0434390904903412 \n",
            " Training accuracy:36.488887786865234 Validation Accuracy: 42.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:11, Training Loss:17.77769034249442 Validation Loss: 1.0386480576992034 \n",
            " Training accuracy:37.733333587646484 Validation Accuracy: 42.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:12, Training Loss:17.71125731468201 Validation Loss: 1.057536291360855 \n",
            " Training accuracy:41.20000076293945 Validation Accuracy: 43.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:13, Training Loss:17.459755665915353 Validation Loss: 1.028122375011444 \n",
            " Training accuracy:39.28889083862305 Validation Accuracy: 44.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:14, Training Loss:17.296015051433017 Validation Loss: 1.0165270316600798 \n",
            " Training accuracy:38.88888931274414 Validation Accuracy: 45.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:15, Training Loss:17.404802233832225 Validation Loss: 1.0514183490276336 \n",
            " Training accuracy:38.57777786254883 Validation Accuracy: 44.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:16, Training Loss:17.10291132926941 Validation Loss: 1.0356270213127137 \n",
            " Training accuracy:40.22222137451172 Validation Accuracy: 48.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:17, Training Loss:16.89223826272147 Validation Loss: 1.0434748895168304 \n",
            " Training accuracy:40.57777786254883 Validation Accuracy: 45.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:18, Training Loss:16.667073713030135 Validation Loss: 1.026412590265274 \n",
            " Training accuracy:42.79999923706055 Validation Accuracy: 45.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:19, Training Loss:16.937832171576364 Validation Loss: 1.0088023760318756 \n",
            " Training accuracy:40.400001525878906 Validation Accuracy: 44.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:20, Training Loss:16.64894230025155 Validation Loss: 1.0259367628097533 \n",
            " Training accuracy:42.79999923706055 Validation Accuracy: 46.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:21, Training Loss:16.023714869362966 Validation Loss: 1.0243138825893403 \n",
            " Training accuracy:46.266666412353516 Validation Accuracy: 49.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:22, Training Loss:16.107382658549717 Validation Loss: 0.9878776512145996 \n",
            " Training accuracy:46.88888931274414 Validation Accuracy: 54.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:23, Training Loss:15.831725536073957 Validation Loss: 1.0248837004899978 \n",
            " Training accuracy:46.0444450378418 Validation Accuracy: 51.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:24, Training Loss:15.783789144243514 Validation Loss: 0.9544378848075866 \n",
            " Training accuracy:49.11111068725586 Validation Accuracy: 56.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:25, Training Loss:15.49731136730739 Validation Loss: 0.9911211726665496 \n",
            " Training accuracy:51.46666717529297 Validation Accuracy: 56.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:26, Training Loss:15.490616532734462 Validation Loss: 0.9551206378936767 \n",
            " Training accuracy:51.02222442626953 Validation Accuracy: 60.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:27, Training Loss:14.830298791612897 Validation Loss: 0.937287466287613 \n",
            " Training accuracy:56.93333435058594 Validation Accuracy: 57.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:28, Training Loss:14.378619847978864 Validation Loss: 0.9143199647665023 \n",
            " Training accuracy:57.82222366333008 Validation Accuracy: 60.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:29, Training Loss:14.570754473549979 Validation Loss: 0.9005248407125473 \n",
            " Training accuracy:56.088890075683594 Validation Accuracy: 59.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:30, Training Loss:14.15606974874224 Validation Loss: 1.063038808465004 \n",
            " Training accuracy:59.333335876464844 Validation Accuracy: 53.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:31, Training Loss:14.684368365151542 Validation Loss: 0.9116120362281799 \n",
            " Training accuracy:56.844444274902344 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:32, Training Loss:14.269959013802664 Validation Loss: 0.8579043331742287 \n",
            " Training accuracy:58.622222900390625 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:33, Training Loss:13.878507995605469 Validation Loss: 0.8809639666676521 \n",
            " Training accuracy:60.0444450378418 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:34, Training Loss:13.358961037227086 Validation Loss: 0.8859215494692325 \n",
            " Training accuracy:61.68888854980469 Validation Accuracy: 58.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:35, Training Loss:12.625915615899222 Validation Loss: 0.8679346297681332 \n",
            " Training accuracy:64.75555419921875 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:36, Training Loss:13.021604251861572 Validation Loss: 1.0119433936178683 \n",
            " Training accuracy:62.13333511352539 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:37, Training Loss:13.09353529725756 Validation Loss: 0.8707623334825039 \n",
            " Training accuracy:63.82222366333008 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:38, Training Loss:12.608390852383204 Validation Loss: 0.8834127492010594 \n",
            " Training accuracy:64.35555267333984 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:39, Training Loss:12.652884217670985 Validation Loss: 0.846448476612568 \n",
            " Training accuracy:64.13333129882812 Validation Accuracy: 66.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:40, Training Loss:12.69187023980277 Validation Loss: 1.0215375687479973 \n",
            " Training accuracy:65.24444580078125 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:41, Training Loss:12.437688435826983 Validation Loss: 0.9679520519673824 \n",
            " Training accuracy:64.53333282470703 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:42, Training Loss:12.137962678500584 Validation Loss: 0.8855277878791094 \n",
            " Training accuracy:65.46666717529297 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:43, Training Loss:12.15780314717974 Validation Loss: 1.1354411448389292 \n",
            " Training accuracy:67.11111450195312 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:44, Training Loss:11.940372538566589 Validation Loss: 0.8335289984196425 \n",
            " Training accuracy:66.5777816772461 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:45, Training Loss:11.816550115176609 Validation Loss: 0.8908004942536354 \n",
            " Training accuracy:68.17778015136719 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:46, Training Loss:11.399507222856794 Validation Loss: 0.9091887817382812 \n",
            " Training accuracy:68.93333435058594 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:47, Training Loss:11.520195514815194 Validation Loss: 0.8511011728197336 \n",
            " Training accuracy:68.66666412353516 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:48, Training Loss:11.48296173300062 Validation Loss: 0.8514465820491314 \n",
            " Training accuracy:69.73333740234375 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:49, Training Loss:11.55440183707646 Validation Loss: 0.8551130311116576 \n",
            " Training accuracy:67.82221984863281 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:50, Training Loss:10.906427802358355 Validation Loss: 0.8945724840536714 \n",
            " Training accuracy:69.86666870117188 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:51, Training Loss:11.075959042140417 Validation Loss: 0.9628537111580372 \n",
            " Training accuracy:69.11111450195312 Validation Accuracy: 61.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:52, Training Loss:10.679558207307544 Validation Loss: 0.9099805696457625 \n",
            " Training accuracy:70.75555419921875 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:53, Training Loss:11.200036542756218 Validation Loss: 0.8748962878510356 \n",
            " Training accuracy:71.15555572509766 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:54, Training Loss:10.72172440290451 Validation Loss: 0.7960305456668139 \n",
            " Training accuracy:70.97777557373047 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:55, Training Loss:10.302052765233176 Validation Loss: 0.9041927613466978 \n",
            " Training accuracy:72.17778015136719 Validation Accuracy: 58.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:56, Training Loss:10.264165888513837 Validation Loss: 0.8768113086894155 \n",
            " Training accuracy:72.53333282470703 Validation Accuracy: 66.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:57, Training Loss:10.186835483142309 Validation Loss: 1.0608509114980698 \n",
            " Training accuracy:72.8888931274414 Validation Accuracy: 61.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:58, Training Loss:10.253134264264787 Validation Loss: 0.9490874673761427 \n",
            " Training accuracy:72.71111297607422 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:59, Training Loss:10.53081476518086 Validation Loss: 1.2962823613360523 \n",
            " Training accuracy:71.46666717529297 Validation Accuracy: 55.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:60, Training Loss:10.007995552676064 Validation Loss: 0.9138470204547048 \n",
            " Training accuracy:74.93333435058594 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:61, Training Loss:10.280181889874594 Validation Loss: 1.1584774052836 \n",
            " Training accuracy:72.93333435058594 Validation Accuracy: 56.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:62, Training Loss:9.95531702382224 Validation Loss: 0.9112734861224889 \n",
            " Training accuracy:73.33333587646484 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:63, Training Loss:10.162633240222931 Validation Loss: 0.9474654443711042 \n",
            " Training accuracy:73.37777709960938 Validation Accuracy: 66.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:64, Training Loss:9.919761332443782 Validation Loss: 0.8471705227121711 \n",
            " Training accuracy:73.64444732666016 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:65, Training Loss:9.394410926955088 Validation Loss: 0.8642724462039769 \n",
            " Training accuracy:76.0888900756836 Validation Accuracy: 66.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:66, Training Loss:9.882015522888729 Validation Loss: 0.8810734300538897 \n",
            " Training accuracy:74.80000305175781 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:67, Training Loss:9.646967950889042 Validation Loss: 0.8707873175330461 \n",
            " Training accuracy:74.80000305175781 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:68, Training Loss:9.416460818052292 Validation Loss: 0.9454255571626127 \n",
            " Training accuracy:74.93333435058594 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:69, Training Loss:9.203252736159733 Validation Loss: 0.9120132431089878 \n",
            " Training accuracy:77.11111450195312 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:70, Training Loss:9.224115111998149 Validation Loss: 0.8933796952683478 \n",
            " Training accuracy:76.4888916015625 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:71, Training Loss:9.017119237354823 Validation Loss: 0.9365254633035511 \n",
            " Training accuracy:76.0888900756836 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:72, Training Loss:9.051929854495185 Validation Loss: 0.9724787675160914 \n",
            " Training accuracy:75.86666870117188 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:73, Training Loss:8.671666819708689 Validation Loss: 0.9455379032455384 \n",
            " Training accuracy:77.33333587646484 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:74, Training Loss:9.107247775793075 Validation Loss: 0.8786404537102207 \n",
            " Training accuracy:75.64444732666016 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:75, Training Loss:8.695712419918605 Validation Loss: 0.9194390951227397 \n",
            " Training accuracy:78.04444885253906 Validation Accuracy: 59.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:76, Training Loss:8.483085093327931 Validation Loss: 0.92086215833202 \n",
            " Training accuracy:77.20000457763672 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:77, Training Loss:8.985832716737475 Validation Loss: 1.1172794276271016 \n",
            " Training accuracy:76.80000305175781 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:78, Training Loss:8.613253891468048 Validation Loss: 0.9507214380223304 \n",
            " Training accuracy:77.86666870117188 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:79, Training Loss:8.21165823681014 Validation Loss: 0.9707786610648036 \n",
            " Training accuracy:78.97777557373047 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:80, Training Loss:8.506111977781568 Validation Loss: 0.9069073066096753 \n",
            " Training accuracy:78.04444885253906 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:81, Training Loss:8.614022728375026 Validation Loss: 1.0372428082488476 \n",
            " Training accuracy:78.53333282470703 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:82, Training Loss:8.138223634447371 Validation Loss: 0.982895652643405 \n",
            " Training accuracy:79.77777862548828 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:83, Training Loss:8.546961012056896 Validation Loss: 0.9667646709224209 \n",
            " Training accuracy:78.04444885253906 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:84, Training Loss:8.062409211908069 Validation Loss: 0.9396028471868485 \n",
            " Training accuracy:80.35555267333984 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:85, Training Loss:8.237756637164525 Validation Loss: 0.9331629527574405 \n",
            " Training accuracy:79.86666870117188 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:86, Training Loss:8.719314801692963 Validation Loss: 0.9698284137761221 \n",
            " Training accuracy:78.80000305175781 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:87, Training Loss:8.12937833411353 Validation Loss: 1.0464747351268306 \n",
            " Training accuracy:78.8888931274414 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:88, Training Loss:7.418411437102726 Validation Loss: 1.007585243104957 \n",
            " Training accuracy:81.77777862548828 Validation Accuracy: 60.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:89, Training Loss:7.522477386678968 Validation Loss: 0.962512337680906 \n",
            " Training accuracy:81.82221984863281 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:90, Training Loss:7.5608989383493155 Validation Loss: 0.9576906710630283 \n",
            " Training accuracy:80.84444427490234 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:91, Training Loss:8.188333958387375 Validation Loss: 1.4245725009962917 \n",
            " Training accuracy:80.26667022705078 Validation Accuracy: 55.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:92, Training Loss:8.135791451590402 Validation Loss: 1.1712334662552457 \n",
            " Training accuracy:79.73333740234375 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:93, Training Loss:7.996670662505286 Validation Loss: 0.8811241145143286 \n",
            " Training accuracy:80.0888900756836 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:94, Training Loss:8.014474368946892 Validation Loss: 1.069821838309057 \n",
            " Training accuracy:80.53333282470703 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:95, Training Loss:7.442395488704954 Validation Loss: 1.056977639551973 \n",
            " Training accuracy:81.82221984863281 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:96, Training Loss:7.4291209476334705 Validation Loss: 1.1164984708649572 \n",
            " Training accuracy:81.68888854980469 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:97, Training Loss:7.584786580290113 Validation Loss: 1.0328160328904632 \n",
            " Training accuracy:81.55555725097656 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:98, Training Loss:7.371881254230227 Validation Loss: 1.1036813300668729 \n",
            " Training accuracy:82.22222137451172 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:99, Training Loss:7.258355918952397 Validation Loss: 1.1599978129126831 \n",
            " Training accuracy:82.4888916015625 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JC_nrAEPd0aQ",
        "outputId": "ce542d92-0303-42b4-ddd3-fbac29f5d887"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_list,'r',valid_loss_list , 'b')\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"], loc =\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQcisxcEpaYB"
      },
      "source": [
        "def get_tensor_from_text_test(text,dataset):\n",
        "    word_list = []\n",
        "    train_word_to_index_dict = get_word_to_index(dataset['text'])\n",
        "    text = text.lower()\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word in train_word_to_index_dict.keys()]\n",
        "    for word in words:\n",
        "        word_list.append(train_word_to_index_dict[word])\n",
        "    if len(word_list) > TEXT_LENGTH:\n",
        "        word_list = word_list[:TEXT_LENGTH]\n",
        "    else:\n",
        "        word_list.extend([0]*(TEXT_LENGTH-len(word_list)))\n",
        "    \n",
        "    tensor_list = torch.tensor(word_list, device=device, dtype=torch.long)\n",
        "    return tensor_list\n",
        "\n",
        "class WeebitTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,test_dataset,train_dataset):\n",
        "        self.dataset = test_dataset\n",
        "        self.train_dataset = train_dataset \n",
        "    \n",
        "    def __getitem__(self,index): \n",
        "        text = self.dataset['text'].iloc[index]\n",
        "        x = get_tensor_from_text_test(text,self.train_dataset)\n",
        "        y = torch.tensor(self.dataset['readability'].iloc[index],dtype=torch.float,device=device)\n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def test(dataset):\n",
        "  testloader = torch.utils.data.DataLoader(\n",
        "                      dataset,\n",
        "                      batch_size=1)\n",
        "  with torch.no_grad():   \n",
        "    model = torch.load('/content/drive/MyDrive/Readability_Research_Paper/models/1-cnn_lstm/lstm_63.pkl')\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    target_list = []\n",
        "    output_list = []\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "      inputs, targets = data\n",
        "      # print(targets.item())\n",
        "      target_list.append(targets.item())\n",
        "      targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "      outputs = model(inputs)\n",
        "      output_ids = torch.argmax(outputs, dim=1)\n",
        "      output_list.append(output_ids.item())\n",
        "      # outputs = outputs.squeeze(1)\n",
        "      test_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / len(dataset)\n",
        "    confusion_matrix_calc = confusion_matrix(target_list,output_list)\n",
        "    classification_report_calc = classification_report(target_list,output_list)\n",
        "    return test_accuracy, confusion_matrix_calc, classification_report_calc"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXngB7mm9G9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59005b1f-ca15-416d-9a6a-01dda9e86a7b"
      },
      "source": [
        "weebit_test_dataset = WeebitTestDataset(test_dataset, train_dataset)\n",
        "accuracy, confusion_matrix_calc, classification_report_calc = test(weebit_test_dataset)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIP5MhfG9XjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631a85a8-6f5f-40c5-9397-96c1c4f2481c"
      },
      "source": [
        "print(\"Testing accuracy is: \" + str(accuracy.item()))\n",
        "print(\"\\nConfusion Matrix\")\n",
        "print(confusion_matrix_calc)\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report_calc)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy is: 64.60000610351562\n",
            "\n",
            "Confusion Matrix\n",
            "[[73 18  8  1  0]\n",
            " [32 50 17  0  1]\n",
            " [17 48 31  2  2]\n",
            " [ 2  1  8 83  6]\n",
            " [ 1  1  1 11 86]]\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      0.73      0.65       100\n",
            "         1.0       0.42      0.50      0.46       100\n",
            "         2.0       0.48      0.31      0.38       100\n",
            "         3.0       0.86      0.83      0.84       100\n",
            "         4.0       0.91      0.86      0.88       100\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.65      0.65      0.64       500\n",
            "weighted avg       0.65      0.65      0.64       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtl34zWrN6Lz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}