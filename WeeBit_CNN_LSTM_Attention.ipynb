{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "WeeBit_CNN_LSTM_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m607stars/Reading-WeeBit-with-LSTMs-CNNs/blob/main/WeeBit_CNN_LSTM_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVC6j9XOC0J1"
      },
      "source": [
        "# Imports and Installs\n",
        "\n",
        "Note: DO NOT forget to change the path for saving models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Upcb-2aDVp3I",
        "outputId": "60b5c46e-8ff0-43ff-e2c6-bc6a8d50b6b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:20.192187Z",
          "iopub.execute_input": "2021-06-17T13:04:20.192588Z",
          "iopub.status.idle": "2021-06-17T13:04:20.196832Z",
          "shell.execute_reply.started": "2021-06-17T13:04:20.192493Z",
          "shell.execute_reply": "2021-06-17T13:04:20.195993Z"
        },
        "trusted": true,
        "id": "4DDm-bAEC0KA"
      },
      "source": [
        "# !pip install torchviz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:31.917757Z",
          "iopub.execute_input": "2021-06-17T13:04:31.91814Z",
          "iopub.status.idle": "2021-06-17T13:04:34.255424Z",
          "shell.execute_reply.started": "2021-06-17T13:04:31.918108Z",
          "shell.execute_reply": "2021-06-17T13:04:34.25454Z"
        },
        "trusted": true,
        "id": "R7_VU3rsC0KD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext import vocab\n",
        "import random\n",
        "import nltk\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wCKUBIfaWyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2a0400-d7b5-4500-a48b-22f0b1b32fee"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJNC91OVSJow",
        "outputId": "06f31ad1-14b8-4300-ee3e-d9e846156ef3"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    print(\"Seeding done\")\n",
        "seed_everything(42)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seeding done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:04:34.257209Z",
          "iopub.execute_input": "2021-06-17T13:04:34.257534Z",
          "iopub.status.idle": "2021-06-17T13:05:23.83085Z",
          "shell.execute_reply.started": "2021-06-17T13:04:34.257499Z",
          "shell.execute_reply": "2021-06-17T13:05:23.829972Z"
        },
        "trusted": true,
        "id": "HVrapbC9C0KE"
      },
      "source": [
        "VECTOR_PATH = '/content/drive/MyDrive/Readability_Research_Paper/'\n",
        "VECTOR_NAME = 'glove.6B.300d.txt'\n",
        "\n",
        "TEXT_LENGTH = 187\n",
        "EMBEDDING_SIZE = 300\n",
        "HIDDEN_SIZE = 200\n",
        "BATCH_SIZE=16\n",
        "\n",
        "embeddings = vocab.Vectors(VECTOR_NAME,VECTOR_PATH)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:23.832382Z",
          "iopub.execute_input": "2021-06-17T13:05:23.832712Z",
          "iopub.status.idle": "2021-06-17T13:05:23.913894Z",
          "shell.execute_reply.started": "2021-06-17T13:05:23.832671Z",
          "shell.execute_reply": "2021-06-17T13:05:23.912978Z"
        },
        "trusted": true,
        "id": "n-hproQLC0KF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9d473f-bc2a-4893-b443-01df4b577aba"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:23.915185Z",
          "iopub.execute_input": "2021-06-17T13:05:23.915509Z",
          "iopub.status.idle": "2021-06-17T13:05:24.025958Z",
          "shell.execute_reply.started": "2021-06-17T13:05:23.915472Z",
          "shell.execute_reply": "2021-06-17T13:05:24.025147Z"
        },
        "trusted": true,
        "id": "6f-ITJlLC0KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "45e0dfd8-706b-4fd9-b30c-0097bd495cb2"
      },
      "source": [
        "train_dataset = pd.read_csv('/content/drive/MyDrive/Readability_Research_Paper/train.csv')\n",
        "train_dataset['readability'] = train_dataset['readability'].apply(lambda x: x-2)\n",
        "train_dataset.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they sent me a salwar kameezpeacockblueand ano...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the chart shows each planet and its number of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>this revision bite will help you understand wh...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what are powers and roots find out how they work</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the wright brothers flew the first airplane ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  readability\n",
              "0  they sent me a salwar kameezpeacockblueand ano...            4\n",
              "1  the chart shows each planet and its number of ...            0\n",
              "2  this revision bite will help you understand wh...            4\n",
              "3   what are powers and roots find out how they work            3\n",
              "4  the wright brothers flew the first airplane ne...            0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:24.027208Z",
          "iopub.execute_input": "2021-06-17T13:05:24.027531Z",
          "iopub.status.idle": "2021-06-17T13:05:24.047821Z",
          "shell.execute_reply.started": "2021-06-17T13:05:24.027495Z",
          "shell.execute_reply": "2021-06-17T13:05:24.047052Z"
        },
        "trusted": true,
        "id": "jPeUbL3eC0KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c41af70c-d19c-4b9e-af94-201ec82c7d79"
      },
      "source": [
        "test_dataset = pd.read_csv('/content/drive/MyDrive/Readability_Research_Paper/test.csv')\n",
        "test_dataset['readability'] = test_dataset['readability'].apply(lambda x: x-2)\n",
        "test_dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>readability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>to understand a work of art or a beautiful obj...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>perhaps the most important of these is the use...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>q what is a tornados favorite game a twister</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the final thing to remember is there are lots ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3d shapes have 3dimensions length width and de...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  readability\n",
              "0  to understand a work of art or a beautiful obj...            4\n",
              "1  perhaps the most important of these is the use...            4\n",
              "2       q what is a tornados favorite game a twister            0\n",
              "3  the final thing to remember is there are lots ...            4\n",
              "4  3d shapes have 3dimensions length width and de...            3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27-DvDgAC0KH"
      },
      "source": [
        "# Data pre-processing and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:05:25.130689Z",
          "iopub.execute_input": "2021-06-17T13:05:25.131097Z",
          "iopub.status.idle": "2021-06-17T13:05:25.236336Z",
          "shell.execute_reply.started": "2021-06-17T13:05:25.131052Z",
          "shell.execute_reply": "2021-06-17T13:05:25.235398Z"
        },
        "trusted": true,
        "id": "_JAJiGSIC0KJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6529d96-8c1f-43d6-a5d9-55086f5bf1a5"
      },
      "source": [
        "def get_word_to_index(texts):\n",
        "    word_to_index = {\n",
        "        '<PAD>':0,\n",
        "        '<START>':1,\n",
        "        '<END>':2,\n",
        "    }\n",
        "    ind = 3\n",
        "    for text in texts:\n",
        "        words = word_tokenize(text)\n",
        "        for word in words:\n",
        "            if word not in word_to_index.keys():\n",
        "                word_to_index[word] = ind\n",
        "                ind += 1\n",
        "                \n",
        "    return word_to_index   \n",
        "\n",
        "word_to_index_dict = get_word_to_index(train_dataset['text'])\n",
        "VOCABULARY_SIZE = len(word_to_index_dict.keys())\n",
        "print(VOCABULARY_SIZE)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:06:02.472213Z",
          "iopub.execute_input": "2021-06-17T13:06:02.472542Z",
          "iopub.status.idle": "2021-06-17T13:06:02.49165Z",
          "shell.execute_reply.started": "2021-06-17T13:06:02.472511Z",
          "shell.execute_reply": "2021-06-17T13:06:02.49062Z"
        },
        "trusted": true,
        "id": "33P8dmcMC0KJ"
      },
      "source": [
        "def get_tensor_from_text(text):\n",
        "    word_list = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        word_list.append(word_to_index_dict[word])\n",
        "    if len(word_list) > TEXT_LENGTH:\n",
        "        word_list = word_list[:TEXT_LENGTH]\n",
        "    else:\n",
        "        word_list.extend([0]*(TEXT_LENGTH-len(word_list)))\n",
        "    \n",
        "    tensor_list = torch.tensor(word_list, device=device, dtype=torch.long)\n",
        "    return tensor_list"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:06:04.311629Z",
          "iopub.execute_input": "2021-06-17T13:06:04.311985Z",
          "iopub.status.idle": "2021-06-17T13:06:04.317795Z",
          "shell.execute_reply.started": "2021-06-17T13:06:04.311954Z",
          "shell.execute_reply": "2021-06-17T13:06:04.31686Z"
        },
        "trusted": true,
        "id": "kL2XMh6hC0KK"
      },
      "source": [
        "class WeebitDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,dataset):\n",
        "        self.dataset = dataset\n",
        "    \n",
        "    def __getitem__(self,index): \n",
        "        text = self.dataset['text'].iloc[index]\n",
        "        y = torch.tensor(self.dataset['readability'].iloc[index],dtype=torch.float,device=device)\n",
        "        x = get_tensor_from_text(text)\n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M_DsPplMbRI"
      },
      "source": [
        "def create_embedding_matrix(embeddings,vocabulary_size):  \n",
        "    embedding_matrix = np.random.rand(vocabulary_size,EMBEDDING_SIZE)\n",
        "    for string,index in word_to_index_dict.items():\n",
        "        if not  all(x == 0 for x in embeddings[string].tolist()):\n",
        "            embedding_matrix[index] = embeddings[string] \n",
        "    return embedding_matrix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q25Fe9HYumo"
      },
      "source": [
        "embedding_matrix = create_embedding_matrix(embeddings,VOCABULARY_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcEGq9VHC0KL"
      },
      "source": [
        "# Model and Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2mjxZHn8JF6"
      },
      "source": [
        "## Done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktrWzCQLHjjV"
      },
      "source": [
        "class ReadabilityModel_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,5)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(x)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        output = linear_output_2\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-06T13:45:54.561125Z",
          "iopub.execute_input": "2021-06-06T13:45:54.561523Z",
          "iopub.status.idle": "2021-06-06T13:45:54.576383Z",
          "shell.execute_reply.started": "2021-06-06T13:45:54.561489Z",
          "shell.execute_reply": "2021-06-06T13:45:54.574846Z"
        },
        "trusted": true,
        "id": "f2l13b1hC0KN"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=187,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()       \n",
        "        self.output_layer = torch.nn.Linear(50,5)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpJpUULo8Uzj"
      },
      "source": [
        "## Current"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T08:42:03.11576Z",
          "iopub.status.idle": "2021-06-17T08:42:03.116141Z"
        },
        "trusted": true,
        "id": "O-EhfRx3C0KL"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.lstm_layer = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(hidden_size,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,5)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU() \n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,187,300\n",
        "        x = x.permute(0,2,1) #shape of x is 16,300,187\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,300,185\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,300,61\n",
        "        conv_output = conv_output_2.permute(0,2,1)\n",
        "        lstm_output, (ht, ct) = self.lstm_layer(conv_output)\n",
        "        #Shape of lstm_output_1 is 16,300,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        output = linear_output_4\n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fxt1r0eIKHB"
      },
      "source": [
        "## To be done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUEILot8TH1"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers):\n",
        "        super().__init__()\n",
        "        self.dropout_probability = 0.2\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers, dropout=self.dropout_probability,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_probability)\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.output_layer = torch.nn.Linear(187,5)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,187,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_3 = self.leaky_relu(linear_output_3)\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_M-nxJEC0KO"
      },
      "source": [
        "# Talha\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=200,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_1 = torch.nn.Linear(512,256)\n",
        "        self.linear_layer_2 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_3 = torch.nn.Linear(64,16)\n",
        "        self.linear_layer_4 = torch.nn.Linear(16,1)       \n",
        "        self.output_layer = torch.nn.Linear(50,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "#         final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,50,1024\n",
        "        linear_output_1 = self.linear_layer_1(word_context)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)\n",
        "        linear_output_4 = linear_output_4.squeeze(2)\n",
        "        output = self.output_layer(linear_output_4)\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.7848541466199805\n",
        "# Lowest Validation loss is 0.7264222720253899 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-06T11:18:35.92226Z",
          "iopub.execute_input": "2021-06-06T11:18:35.925335Z",
          "iopub.status.idle": "2021-06-06T11:18:35.964619Z",
          "shell.execute_reply.started": "2021-06-06T11:18:35.925277Z",
          "shell.execute_reply": "2021-06-06T11:18:35.96208Z"
        },
        "trusted": true,
        "id": "E4_gghJNC0KP"
      },
      "source": [
        "# Mayank\n",
        "\n",
        "class ReadabilityModel_CNN_LSTM_Attention_LSTM(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=200,out_channels=100,kernel_size=1,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=100,out_channels=50,kernel_size=1,stride=1)\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(300, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.linear_layer_embedding_context = torch.nn.Linear(1024,512)\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(512, hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, bidirectional=True)\n",
        "        self.linear_layer_1 = torch.nn.Linear(256,128)\n",
        "        self.linear_layer_2 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_3 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_4 = torch.nn.Linear(8,1)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=0.1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        conv_output_1 = self.conv_layer_1(x) #shape of conv_output_1 is 16,100,300\n",
        "        conv_output_1 = self.dropout_layer(conv_output_1)\n",
        "        conv_output_2 = self.conv_layer_2(conv_output_1) #shape of conv_output_2 is 16,50,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(conv_output_2)\n",
        "        #Shape of lstm_output_1 is 16,50,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        attention_output = self.attention_layer(ht1[-1])\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,50,512\n",
        "        attention_context = self.dropout_layer(attention_context)\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,50,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,50,512\n",
        "        final_context_words = word_context*lstm_output_1  #Shape is 16,50,512\n",
        "        lstm_output_2, (ht2, ct2) = self.lstm_layer_2(final_context_words)\n",
        "        #Shape of lstm_output_2 is 16,50,1024 \n",
        "        #Shape of ht2 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht2[-1])     #Shape is 16,128\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)   #Shape is 16,32\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)   #Shape is 16,8\n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)   #Shape is 16,1\n",
        "        output = linear_output_4   #Shape of output is 16,1\n",
        "        return output\n",
        "    \n",
        "# Average Validation Loss:0.9133829620398682 \n",
        "# Lowest Validation Loss: 0.8187914316807785 at fold 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-12T15:39:47.24523Z",
          "iopub.execute_input": "2021-06-12T15:39:47.245841Z",
          "iopub.status.idle": "2021-06-12T15:39:47.264813Z",
          "shell.execute_reply.started": "2021-06-12T15:39:47.245786Z",
          "shell.execute_reply": "2021-06-12T15:39:47.264052Z"
        },
        "trusted": true,
        "id": "dfpZBqlSC0KQ"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer_1 = torch.nn.Linear(3072,1024)\n",
        "        self.conv_output_linear_layer_2 = torch.nn.Linear(1024,256)\n",
        "        self.conv_output_linear_layer_3 = torch.nn.Linear(256,32)\n",
        "        self.conv_output_linear_layer_4 = torch.nn.Linear(32,8)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.conv_output_linear_layer_5 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_1 = torch.nn.Linear(128,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        final_context_words = final_context_words.permute(0,2,1)\n",
        "        conv_output_1 = self.conv_layer_1(final_context_words)       #Shape is 16,1024,198\n",
        "        conv_output_2 = self.conv_layer_2(final_context_words)       #Shape is 16,1024,66\n",
        "        conv_output_3 = self.conv_layer_3(final_context_words)       #Shape is 16,1024,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,1024,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,1024,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,1024,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,3072,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,3072\n",
        "        conv_linear_output_1 = self.conv_output_linear_layer_1(conv_output)  #Shape is 16,128,1024\n",
        "        conv_linear_output_2 = self.conv_output_linear_layer_2(conv_linear_output_1)#Shape is 16,128,256\n",
        "        conv_linear_output_2 = self.tanh(conv_linear_output_2)\n",
        "        conv_linear_output_3 = self.conv_output_linear_layer_3(conv_linear_output_2)\n",
        "        conv_linear_output_4 = self.conv_output_linear_layer_4(conv_linear_output_3)\n",
        "        conv_linear_output_4 = self.tanh(conv_linear_output_4)\n",
        "        conv_linear_output_5 = self.conv_output_linear_layer_5(conv_linear_output_4)\n",
        "        conv_linear_output_5 = conv_linear_output_5.squeeze(2)\n",
        "        linear_output_1 = self.linear_layer_1(conv_linear_output_5)  #Shape is 16,64\n",
        "        linear_output_1 = self.tanh(linear_output_1)\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,1\n",
        "        output = linear_output_2   #Shape of output is 16,1\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:0.6796757201937529\n",
        "# Lowest validation loss is 0.6500918945654444 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-09T03:23:10.046616Z",
          "iopub.execute_input": "2021-06-09T03:23:10.047071Z",
          "iopub.status.idle": "2021-06-09T03:23:10.081609Z",
          "shell.execute_reply.started": "2021-06-09T03:23:10.047033Z",
          "shell.execute_reply": "2021-06-09T03:23:10.080605Z"
        },
        "trusted": true,
        "id": "FhFL925rC0KS"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_LSTM_Attention_CNN_GRU(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=1024,out_channels=1024,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer_1 = torch.nn.Linear(3072,1024)\n",
        "        self.conv_output_linear_layer_2 = torch.nn.Linear(1024,256)\n",
        "        self.gru_layer = torch.nn.GRU(256,hidden_size,num_layers=num_of_layers,batch_first=True,\n",
        "                                     dropout=self.dropout_prob)\n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        final_context_words = final_context_words.permute(0,2,1)\n",
        "        conv_output_1 = self.conv_layer_1(final_context_words)       #Shape is 16,1024,198\n",
        "        conv_output_2 = self.conv_layer_2(final_context_words)       #Shape is 16,1024,66\n",
        "        conv_output_3 = self.conv_layer_3(final_context_words)       #Shape is 16,1024,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,1024,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,1024,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,1024,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,3072,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,3072\n",
        "        conv_linear_output_1 = self.conv_output_linear_layer_1(conv_output)  #Shape is 16,128,1024\n",
        "        conv_linear_output_2 = self.conv_output_linear_layer_2(conv_linear_output_1)#Shape is 16,128,256\n",
        "        gru_output , ht = self.gru_layer(conv_linear_output_2)\n",
        "        #Shape of ht is 16,256\n",
        "        linear_output_1 = self.linear_layer_1(ht[-1])  #Shape is 16,64\n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,8\n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,1\n",
        "        output = linear_output_3   #Shape of output is 16,1\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:1.0334918799897828\n",
        "# Lowest avalidation loss is 1.013418031971577 at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-07T14:56:01.375534Z",
          "iopub.execute_input": "2021-06-07T14:56:01.376153Z",
          "iopub.status.idle": "2021-06-07T14:56:01.401621Z",
          "shell.execute_reply.started": "2021-06-07T14:56:01.376099Z",
          "shell.execute_reply": "2021-06-07T14:56:01.400629Z"
        },
        "trusted": true,
        "id": "AroKhpBlC0KT"
      },
      "source": [
        "# mayank\n",
        "\n",
        "class CommonLitCNNLSTMAttention_EnsembleModel(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_layers, batch_size):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "                \n",
        "        self.embedding_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embedding_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix,\n",
        "                                                                      dtype=torch.float32,\n",
        "                                                                      device=device))\n",
        "        self.embedding_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1],hidden_size,\n",
        "                                          batch_first = True,num_layers = self.num_layers,\n",
        "                                          bidirectional=True)        \n",
        "        self.attention_linear_layer = torch.nn.Linear(hidden_size,2*hidden_size)\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(4*hidden_size,hidden_size,\n",
        "                                          batch_first=True,num_layers = self.num_layers,\n",
        "                                          bidirectional=True)\n",
        "        \n",
        "        # Block 2\n",
        "        self.lstm_layer_3 = torch.nn.LSTM(embedding_matrix.shape[1],hidden_size,\n",
        "                                    batch_first = True,num_layers = self.num_layers,\n",
        "                                    bidirectional=True)        \n",
        "        self.conv1 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=3,stride=1)\n",
        "        self.conv2 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=5,stride=1)\n",
        "        self.conv3 = torch.nn.Conv1d(in_channels = 2*hidden_size, out_channels=hidden_size,\n",
        "                               kernel_size=7,stride=1)\n",
        "        self.low_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                batch_first = True,num_layers = self.num_layers,\n",
        "                                bidirectional=True)\n",
        "        self.med_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                batch_first = True,num_layers = self.num_layers,\n",
        "                                bidirectional=True)\n",
        "        self.high_lstm = torch.nn.LSTM(hidden_size,hidden_size,\n",
        "                                 batch_first = True,num_layers = self.num_layers,\n",
        "                                 bidirectional=True)\n",
        "        self.lstm_features_concat_layer = torch.nn.Linear(3*hidden_size,hidden_size)\n",
        "\n",
        "        #Combining Block 1 and 2\n",
        "        self.output_linear_1 = torch.nn.Linear(2*hidden_size,hidden_size)\n",
        "        self.output_linear_2 = torch.nn.Linear(hidden_size,hidden_size // 2)\n",
        "        self.output_linear_3 = torch.nn.Linear(hidden_size// 2,1)\n",
        "    \n",
        "    \n",
        "    def forward(self,input_text):\n",
        "        self.embeddings = self.embedding_layer(input_text.long().to(device))\n",
        "        self.embeddings = self.embeddings.permute(0, 2, 1)   # convert to [batch, channels, time]\n",
        "        self.embeddings = torch.nn.functional.dropout2d(self.embeddings, 0.2, training=self.training)\n",
        "        self.embeddings = self.embeddings.permute(0, 2, 1)\n",
        "        \n",
        "        #Block 1\n",
        "        lstm_output_1,(hidden_state_1,cell_state) = self.lstm_layer_1(self.embeddings)\n",
        "        final_state_1 = hidden_state_1[-1,:,:]\n",
        "        attention_linear_output = self.attention_linear_layer(final_state_1)\n",
        "        attention_linear_output = attention_linear_output.unsqueeze(1)\n",
        "        attention_multiplied_context = lstm_output_1 * attention_linear_output\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_multiplied_context,dim=1)\n",
        "        global_context = softmax_attention * lstm_output_1\n",
        "        final_context_words = torch.cat([global_context,lstm_output_1],dim=2) # 64,seq_len,4*hidden_size\n",
        "        lstm_output_2, (hidden_state_2,cell_state_2) = self.lstm_layer_2(final_context_words)\n",
        "        final_state_2 = hidden_state_2[-1,:,:]\n",
        "\n",
        "        #Block 2\n",
        "        lstm_output_3,(hidden_state_3,cell_state_3) = self.lstm_layer_3(self.embeddings)\n",
        "        lstm_output_3 = lstm_output_3.permute(0,2,1)\n",
        "        \n",
        "        conv_1_output = self.conv1(lstm_output_3)\n",
        "        conv_1_output = conv_1_output.permute(0,2,1) \n",
        "\n",
        "        conv_2_output = self.conv2(lstm_output_3)\n",
        "        conv_2_output = conv_2_output.permute(0,2,1)\n",
        "        \n",
        "        conv_3_output = self.conv3(lstm_output_3)\n",
        "        conv_3_output = conv_3_output.permute(0,2,1)\n",
        "\n",
        "        low_lstm_output,(hidden_state_low,cell_state_low) = self.low_lstm(conv_1_output)\n",
        "        med_lstm_output,(hidden_state_med,cell_state_med) = self.med_lstm(conv_2_output)\n",
        "        high_lstm_output,(hidden_state_high,cell_state_high) = self.high_lstm(conv_3_output)\n",
        "        concat_features = torch.cat([hidden_state_low[-1,:,:],hidden_state_med[-1,:,:],hidden_state_high[-1,:,:]],dim=1)\n",
        "        lstm_linear_concat_output = self.lstm_features_concat_layer(concat_features)\n",
        "\n",
        "        #Combining BLock 1 and 2 \n",
        "        short_long_context_features = torch.cat([final_state_2,lstm_linear_concat_output],dim=1)\n",
        "        linear_output_1 = self.output_linear_1(short_long_context_features)\n",
        "        linear_output_2 = self.output_linear_2(linear_output_1)\n",
        "        linear_output_3 = self.output_linear_3(linear_output_2)\n",
        "\n",
        "        return linear_output_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T10:16:38.008865Z",
          "iopub.execute_input": "2021-06-17T10:16:38.009177Z",
          "iopub.status.idle": "2021-06-17T10:16:38.03138Z",
          "shell.execute_reply.started": "2021-06-17T10:16:38.009147Z",
          "shell.execute_reply": "2021-06-17T10:16:38.03056Z"
        },
        "trusted": true,
        "id": "FzjZtmZvC0KU"
      },
      "source": [
        "# mayank\n",
        "\n",
        "class ReadabilityModel_parallel_LSTM_Attention_and_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.lstm_linear_layer = torch.nn.Linear(1024,256)\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=300,out_channels=300,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer = torch.nn.Linear(900,256)\n",
        "        \n",
        "        # Combining both the blocks \n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_4 = torch.nn.Linear(328,128)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_7 = torch.nn.Linear(8,1)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_prob)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        block_1_output = self.lstm_linear_layer(final_context_words)  #Shape is 16,200,256\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        x_permuted = x.permute(0,2,1)   #Shape is 16,300,200\n",
        "        conv_output_1 = self.conv_layer_1(x_permuted)       #Shape is 16,300,198\n",
        "        conv_output_2 = self.conv_layer_2(x_permuted)       #Shape is 16,300,66\n",
        "        conv_output_3 = self.conv_layer_3(x_permuted)       #Shape is 16,300,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,300,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,300,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,300,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,900,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,900\n",
        "        block_2_output = self.conv_output_linear_layer(conv_output)  #Shape is 16,128,256\n",
        "        \n",
        "        # Combining block 1 & 2\n",
        "        concatenated_output = torch.cat([block_1_output,block_2_output],dim=1)  #Shape is 16,328,256\n",
        "        linear_output_1 = self.linear_layer_1(concatenated_output)  #Shape is 16,328,64\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        \n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,328,8\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        \n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,328,1\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_3 = linear_output_3.squeeze(2)            #Shape is 16,328\n",
        "        \n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)  #Shape is 16,128\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        \n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)  #Shape is 16,32\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)        \n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "        \n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)  #Shape is 16,8\n",
        "        linear_output_6 = self.dropout_layer(linear_output_6)\n",
        "\n",
        "        linear_output_7 = self.linear_layer_7(linear_output_6)  #Shape is 16,1\n",
        "        output = linear_output_7\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:\n",
        "# Lowest validation loss is  at fold 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:07:03.522849Z",
          "iopub.execute_input": "2021-06-17T13:07:03.523228Z",
          "iopub.status.idle": "2021-06-17T13:07:03.546108Z",
          "shell.execute_reply.started": "2021-06-17T13:07:03.523197Z",
          "shell.execute_reply": "2021-06-17T13:07:03.544794Z"
        },
        "trusted": true,
        "id": "PMCdF2WAC0KU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "7d9f3c34-275c-45a5-fa80-19749118e382"
      },
      "source": [
        "# talha\n",
        "\n",
        "class ReadabilityModel_parallel_LSTM_Attention_and_LSTM_CNN(torch.nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size, num_of_layers, batch_size, training):\n",
        "        super().__init__()\n",
        "        if training:\n",
        "            self.dropout_prob = 0.2\n",
        "        else:\n",
        "            self.dropout_prop = 0.0\n",
        "        self.embeddings_layer = torch.nn.Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
        "                                                   padding_idx=0)\n",
        "        self.embeddings_layer.weight = torch.nn.Parameter(torch.tensor(embedding_matrix, \n",
        "                                                                       dtype=torch.float32,\n",
        "                                                                       device=device))\n",
        "        self.embeddings_layer.weight.requires_grad = False\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        self.lstm_layer_1 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.attention_layer = torch.nn.Linear(hidden_size,hidden_size*2)\n",
        "        self.lstm_linear_layer = torch.nn.Linear(1024,256)\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        self.lstm_layer_2 = torch.nn.LSTM(embedding_matrix.shape[1], hidden_size,\n",
        "                                        num_layers=num_of_layers,\n",
        "                                        batch_first=True, dropout=self.dropout_prob,\n",
        "                                        bidirectional=True)\n",
        "        self.conv_layer_1 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=3,stride=1)\n",
        "        self.conv_layer_2 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=5,stride=3)\n",
        "        self.conv_layer_3 = torch.nn.Conv1d(in_channels=512,out_channels=512,kernel_size=11,stride=9)\n",
        "        self.conv_linear_layer_1 = torch.nn.Linear(198,128)\n",
        "        self.conv_linear_layer_2 = torch.nn.Linear(66,128)\n",
        "        self.conv_linear_layer_3 = torch.nn.Linear(22,128)\n",
        "        self.conv_output_linear_layer = torch.nn.Linear(1536,256)\n",
        "        \n",
        "        # Combining both the blocks \n",
        "        self.linear_layer_1 = torch.nn.Linear(256,64)\n",
        "        self.linear_layer_2 = torch.nn.Linear(64,8)\n",
        "        self.linear_layer_3 = torch.nn.Linear(8,1)\n",
        "        self.linear_layer_4 = torch.nn.Linear(328,128)\n",
        "        self.linear_layer_5 = torch.nn.Linear(128,32)\n",
        "        self.linear_layer_6 = torch.nn.Linear(32,8)\n",
        "        self.linear_layer_7 = torch.nn.Linear(8,1)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_prob)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.embeddings_layer(x) #shape of x is 16,200,300\n",
        "        \n",
        "        # Block 1 - Lstm layer block\n",
        "        lstm_output_1, (ht1, ct1) = self.lstm_layer_1(x)\n",
        "        #Shape of lstm_output_1 is 16,200,512 \n",
        "        #Shape of ht1 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht1[-1] is 16,256\n",
        "        attention_output = self.attention_layer(ht1[-1]) #Shape of is 16,512\n",
        "        attention_output = attention_output.unsqueeze(1) #Shape is 16,1,512\n",
        "        attention_context = lstm_output_1 * attention_output #Shape is 16,200,512\n",
        "        softmax_attention = torch.nn.functional.softmax(attention_context,dim=1) #Shape is 16,200,512\n",
        "        word_context = softmax_attention * lstm_output_1  #Shape is 16,200,512\n",
        "        final_context_words = torch.cat([word_context,lstm_output_1],dim=2)  #Shape is 16,200,1024\n",
        "        block_1_output = self.lstm_linear_layer(final_context_words)  #Shape is 16,200,256\n",
        "        \n",
        "        # Block 2 - Conv layer block\n",
        "        lstm_output_2, (ht2, ct2) = self.lstm_layer_2(x)\n",
        "        #Shape of lstm_output_2 is 16,200,512 \n",
        "        #Shape of ht2 is 6,16,256 \n",
        "        #Shape of ct2 is 6,16,256\n",
        "        #Shape of ht2[-1] is 16,256\n",
        "        lstm_output_2_permuted = lstm_output_2.permute(0,2,1)   #Shape is 16,512,200\n",
        "        conv_output_1 = self.conv_layer_1(lstm_output_2_permuted)       #Shape is 16,512,198\n",
        "        conv_output_2 = self.conv_layer_2(lstm_output_2_permuted)       #Shape is 16,512,66\n",
        "        conv_output_3 = self.conv_layer_3(lstm_output_2_permuted)       #Shape is 16,512,22\n",
        "        conv_output_linear_1 = self.conv_linear_layer_1(conv_output_1)  #Shape is 16,512,128\n",
        "        conv_output_linear_2 = self.conv_linear_layer_2(conv_output_2)  #Shape is 16,512,128\n",
        "        conv_output_linear_3 = self.conv_linear_layer_3(conv_output_3)  #Shape is 16,512,128\n",
        "        conv_output = torch.cat([conv_output_linear_1,conv_output_linear_2,conv_output_linear_3],\n",
        "                                dim=1)  #Shape is 16,1536,128\n",
        "        conv_output = conv_output.permute(0,2,1) #Shape is 16,128,1536\n",
        "        block_2_output = self.conv_output_linear_layer(conv_output)  #Shape is 16,128,256\n",
        "        \n",
        "        # Combining block 1 & 2\n",
        "        concatenated_output = torch.cat([block_1_output,block_2_output],dim=1)  #Shape is 16,328,256\n",
        "        linear_output_1 = self.linear_layer_1(concatenated_output)  #Shape is 16,328,64\n",
        "        linear_output_1 = self.leaky_relu(linear_output_1)\n",
        "        linear_output_1 = self.dropout_layer(linear_output_1)\n",
        "        \n",
        "        linear_output_2 = self.linear_layer_2(linear_output_1)  #Shape is 16,328,8\n",
        "        linear_output_2 = self.leaky_relu(linear_output_2)\n",
        "        linear_output_2 = self.dropout_layer(linear_output_2)\n",
        "        \n",
        "        linear_output_3 = self.linear_layer_3(linear_output_2)  #Shape is 16,328,1\n",
        "        linear_output_3 = self.dropout_layer(linear_output_3)\n",
        "        linear_output_3 = linear_output_3.squeeze(2)            #Shape is 16,328\n",
        "        \n",
        "        linear_output_4 = self.linear_layer_4(linear_output_3)  #Shape is 16,128\n",
        "        linear_output_4 = self.leaky_relu(linear_output_4)\n",
        "        linear_output_4 = self.dropout_layer(linear_output_4)\n",
        "        \n",
        "        linear_output_5 = self.linear_layer_5(linear_output_4)  #Shape is 16,32\n",
        "        linear_output_5 = self.leaky_relu(linear_output_5)        \n",
        "        linear_output_5 = self.dropout_layer(linear_output_5)\n",
        "        \n",
        "        linear_output_6 = self.linear_layer_6(linear_output_5)  #Shape is 16,8\n",
        "        linear_output_6 = self.dropout_layer(linear_output_6)\n",
        "\n",
        "        linear_output_7 = self.linear_layer_7(linear_output_6)  #Shape is 16,1\n",
        "        output = linear_output_7\n",
        "        return output\n",
        "\n",
        "# Average Validation Loss:\n",
        "# Lowest validation loss is  at fold 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c0e916e9ab83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mReadabilityModel_parallel_LSTM_Attention_and_LSTM_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ci_ao8XIVWM"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-17T13:07:07.025597Z",
          "iopub.execute_input": "2021-06-17T13:07:07.025948Z",
          "iopub.status.idle": "2021-06-17T17:01:04.936288Z",
          "shell.execute_reply.started": "2021-06-17T13:07:07.025916Z",
          "shell.execute_reply": "2021-06-17T17:01:04.935397Z"
        },
        "trusted": true,
        "id": "H6frPLDYC0KU"
      },
      "source": [
        "def train(train_dataset,valid_dataset,epochs,learning_rate,train_batch_size,valid_batch_size,embedding_matrix,hidden_size, num_of_layers):\n",
        "  loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size,\n",
        "                                            drop_last=True)\n",
        "  validloader = torch.utils.data.DataLoader(valid_dataset,batch_size=valid_batch_size,\n",
        "                                            drop_last=True)\n",
        "\n",
        "  model = ReadabilityModel_CNN_LSTM(embedding_matrix,\n",
        "                                              hidden_size, num_of_layers)\n",
        "  model = model.to(device)\n",
        "  train_loss_list,valid_loss_list = [],[]\n",
        "  train_accuracy_list,valid_accuracy_list = [],[]\n",
        "  for epoch in range(0, epochs):\n",
        "      epoch_loss = 0.0\n",
        "      model.train()\n",
        "      train_correct = 0\n",
        "      # learning_rate = 0.001/(epoch+1)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          inputs, targets = data\n",
        "          optimizer.zero_grad()\n",
        "          targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "          outputs = model(inputs)\n",
        "          output_ids = torch.argmax(outputs, dim=1)\n",
        "\n",
        "          loss = loss_function(outputs, targets)\n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "      train_accuracy = 100 * train_correct / len(train_dataset)\n",
        "      epoch_loss /= len(trainloader) / train_batch_size \n",
        "      train_loss_list.append(epoch_loss)\n",
        "      train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        validation_loss = 0.0\n",
        "        valid_correct = 0\n",
        "        for i, data in enumerate(validloader, 0):\n",
        "            model.eval()\n",
        "            inputs, targets = data\n",
        "            targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "            outputs = model(inputs)\n",
        "            output_ids = torch.argmax(outputs, dim=1)\n",
        "            # outputs = outputs.squeeze(1)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            validation_loss += loss.item()\n",
        "            valid_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "      valid_accuracy = 100 * valid_correct / len(valid_dataset)  \n",
        "      validation_loss /= len(validloader) / valid_batch_size \n",
        "      valid_loss_list.append(validation_loss)\n",
        "      valid_accuracy_list.append(valid_accuracy)\n",
        "      print(f'Epoch:{epoch}, Training Loss:{epoch_loss} Validation Loss: {validation_loss} \\n Training accuracy:{train_accuracy} Validation Accuracy: {valid_accuracy} ')\n",
        "\n",
        "      torch.save(model,'/content/drive/MyDrive/Readability_Research_Paper/models/cnn_lstm/lstm_{}.pkl'.format(epoch))    \n",
        "      print('--------------------------------')\n",
        "\n",
        "  return train_loss_list,valid_loss_list,train_accuracy_list,valid_accuracy_list,model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvueADn3iPQg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "split_train_df, split_val_df = train_test_split(train_dataset,test_size=0.1,stratify=train_dataset['readability'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFBKon58cgZn"
      },
      "source": [
        "train_dataset_torch = WeebitDataset(split_train_df)\n",
        "valid_dataset_torch = WeebitDataset(split_val_df)\n",
        "EMBEDDING_SIZE = 300 \n",
        "hidden_size = 256\n",
        "num_of_layers = 3\n",
        "train_batch_size = 16\n",
        "valid_batch_size = 1\n",
        "epochs = 100\n",
        "learning_rate = 0.00005"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8b6YirPC0KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2bdb02-88e7-4d51-a809-d3a84d6b1ca4"
      },
      "source": [
        "train_loss_list,valid_loss_list,train_accuracy_list,valid_accuracy_list,model = train(train_dataset_torch,valid_dataset_torch,epochs,learning_rate,\n",
        "                                                                                      train_batch_size,valid_batch_size,\n",
        "                                                                                      embedding_matrix,hidden_size,num_of_layers)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Training Loss:25.719456359318325 Validation Loss: 1.5656403617858887 \n",
            " Training accuracy:20.266666412353516 Validation Accuracy: 29.200000762939453 \n",
            "--------------------------------\n",
            "Epoch:1, Training Loss:23.943954876491002 Validation Loss: 1.3882041592597962 \n",
            " Training accuracy:30.53333282470703 Validation Accuracy: 40.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:2, Training Loss:21.133005033220563 Validation Loss: 1.2494257357120513 \n",
            " Training accuracy:37.42222213745117 Validation Accuracy: 44.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:3, Training Loss:19.466389465332032 Validation Loss: 1.1375826787948609 \n",
            " Training accuracy:40.75555419921875 Validation Accuracy: 44.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:4, Training Loss:18.424346767153057 Validation Loss: 1.1335189709663391 \n",
            " Training accuracy:44.088890075683594 Validation Accuracy: 44.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:5, Training Loss:17.87251945904323 Validation Loss: 1.0560805332660674 \n",
            " Training accuracy:44.57777786254883 Validation Accuracy: 47.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:6, Training Loss:17.085889680044993 Validation Loss: 0.999813458442688 \n",
            " Training accuracy:45.60000228881836 Validation Accuracy: 48.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:7, Training Loss:16.750918674468995 Validation Loss: 0.9785819032788277 \n",
            " Training accuracy:48.75555419921875 Validation Accuracy: 50.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:8, Training Loss:16.310718856539044 Validation Loss: 0.9621375116109848 \n",
            " Training accuracy:48.66666793823242 Validation Accuracy: 56.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:9, Training Loss:15.658178561074394 Validation Loss: 0.9775449493527413 \n",
            " Training accuracy:51.733333587646484 Validation Accuracy: 53.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:10, Training Loss:15.396334082739694 Validation Loss: 0.9600709527134895 \n",
            " Training accuracy:52.088890075683594 Validation Accuracy: 54.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:11, Training Loss:15.364967952455792 Validation Loss: 0.9669694389700889 \n",
            " Training accuracy:52.088890075683594 Validation Accuracy: 51.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:12, Training Loss:14.643242965425763 Validation Loss: 0.9216260741055011 \n",
            " Training accuracy:52.844444274902344 Validation Accuracy: 55.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:13, Training Loss:14.419689110347203 Validation Loss: 0.955687922552228 \n",
            " Training accuracy:53.155555725097656 Validation Accuracy: 53.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:14, Training Loss:14.580597955839975 Validation Loss: 0.9100722747892142 \n",
            " Training accuracy:53.377777099609375 Validation Accuracy: 53.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:15, Training Loss:13.841022985322136 Validation Loss: 0.8908551855385304 \n",
            " Training accuracy:54.488887786865234 Validation Accuracy: 56.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:16, Training Loss:13.596052047184536 Validation Loss: 0.9071135309711099 \n",
            " Training accuracy:55.02222442626953 Validation Accuracy: 55.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:17, Training Loss:13.539404773712159 Validation Loss: 0.8850512839332223 \n",
            " Training accuracy:54.488887786865234 Validation Accuracy: 54.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:18, Training Loss:13.456617263385228 Validation Loss: 1.106534069545567 \n",
            " Training accuracy:54.53333282470703 Validation Accuracy: 54.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:19, Training Loss:13.062839770317078 Validation Loss: 1.0137173455283046 \n",
            " Training accuracy:55.77777862548828 Validation Accuracy: 52.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:20, Training Loss:13.059916550772531 Validation Loss: 0.9564424344934523 \n",
            " Training accuracy:57.06666564941406 Validation Accuracy: 51.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:21, Training Loss:13.038844953264508 Validation Loss: 0.9262251155637204 \n",
            " Training accuracy:55.46666717529297 Validation Accuracy: 54.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:22, Training Loss:13.035956076213292 Validation Loss: 0.9356701562218368 \n",
            " Training accuracy:55.377777099609375 Validation Accuracy: 57.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:23, Training Loss:12.910976750510079 Validation Loss: 1.0133511400129647 \n",
            " Training accuracy:56.93333435058594 Validation Accuracy: 56.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:24, Training Loss:13.131915041378566 Validation Loss: 0.9968134213984012 \n",
            " Training accuracy:56.266666412353516 Validation Accuracy: 55.20000076293945 \n",
            "--------------------------------\n",
            "Epoch:25, Training Loss:12.522697135380335 Validation Loss: 0.9907524234466255 \n",
            " Training accuracy:59.20000076293945 Validation Accuracy: 61.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:26, Training Loss:12.335682930265154 Validation Loss: 1.0346546342521905 \n",
            " Training accuracy:60.35555648803711 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:27, Training Loss:12.44196732725416 Validation Loss: 1.1778044294426218 \n",
            " Training accuracy:60.93333435058594 Validation Accuracy: 58.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:28, Training Loss:12.133963114874703 Validation Loss: 0.9698262539245188 \n",
            " Training accuracy:60.88888931274414 Validation Accuracy: 60.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:29, Training Loss:11.960613703727722 Validation Loss: 1.0010760261304676 \n",
            " Training accuracy:62.844444274902344 Validation Accuracy: 61.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:30, Training Loss:11.944269469806127 Validation Loss: 1.0105753578953445 \n",
            " Training accuracy:62.622222900390625 Validation Accuracy: 61.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:31, Training Loss:12.007720545360021 Validation Loss: 0.9834963543722406 \n",
            " Training accuracy:62.31111145019531 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:32, Training Loss:11.473891132218498 Validation Loss: 1.0213631521142088 \n",
            " Training accuracy:64.97777557373047 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:33, Training Loss:11.41942184312003 Validation Loss: 1.161191462080693 \n",
            " Training accuracy:64.66666412353516 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:34, Training Loss:11.541559982299805 Validation Loss: 1.1120916587566025 \n",
            " Training accuracy:65.68888854980469 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:35, Training Loss:11.61642370564597 Validation Loss: 1.0789548575505614 \n",
            " Training accuracy:66.04444885253906 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:36, Training Loss:11.058180924824306 Validation Loss: 1.1304970098705962 \n",
            " Training accuracy:67.37777709960938 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:37, Training Loss:11.003875541687012 Validation Loss: 1.2811055924628163 \n",
            " Training accuracy:67.68888854980469 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:38, Training Loss:11.008941841125488 Validation Loss: 1.1464726131136995 \n",
            " Training accuracy:68.62222290039062 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:39, Training Loss:10.777650458472115 Validation Loss: 1.1039347754848423 \n",
            " Training accuracy:69.15555572509766 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:40, Training Loss:10.466393968037197 Validation Loss: 1.3291260002142518 \n",
            " Training accuracy:70.4888916015625 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:41, Training Loss:10.217776230403356 Validation Loss: 1.227281761637132 \n",
            " Training accuracy:70.22222137451172 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:42, Training Loss:10.058411579472677 Validation Loss: 1.2791057066472713 \n",
            " Training accuracy:71.20000457763672 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:43, Training Loss:10.056641844340733 Validation Loss: 1.387487281843525 \n",
            " Training accuracy:72.31111145019531 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:44, Training Loss:10.047875223840986 Validation Loss: 1.3642817166110908 \n",
            " Training accuracy:73.33333587646484 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:45, Training Loss:9.423861144270216 Validation Loss: 1.5350477364400577 \n",
            " Training accuracy:73.68888854980469 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:46, Training Loss:9.832327861445291 Validation Loss: 1.4609199041021639 \n",
            " Training accuracy:73.55555725097656 Validation Accuracy: 63.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:47, Training Loss:9.34939797946385 Validation Loss: 1.4242437177775136 \n",
            " Training accuracy:74.31111145019531 Validation Accuracy: 61.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:48, Training Loss:9.050591250828335 Validation Loss: 1.2114381807932368 \n",
            " Training accuracy:75.9111099243164 Validation Accuracy: 71.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:49, Training Loss:9.30398519550051 Validation Loss: 1.2565112052026526 \n",
            " Training accuracy:74.97777557373047 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:50, Training Loss:9.186574581691197 Validation Loss: 1.275466884067384 \n",
            " Training accuracy:75.82221984863281 Validation Accuracy: 68.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:51, Training Loss:8.890682855674198 Validation Loss: 1.4016513913214004 \n",
            " Training accuracy:75.46666717529297 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:52, Training Loss:8.73233932682446 Validation Loss: 1.2142461755928744 \n",
            " Training accuracy:76.84444427490234 Validation Accuracy: 69.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:53, Training Loss:8.367398582186018 Validation Loss: 1.2751272965688767 \n",
            " Training accuracy:77.5999984741211 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:54, Training Loss:8.622902206012181 Validation Loss: 1.3897482830613663 \n",
            " Training accuracy:78.26667022705078 Validation Accuracy: 68.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:55, Training Loss:8.33059240239007 Validation Loss: 1.232854181486524 \n",
            " Training accuracy:77.68888854980469 Validation Accuracy: 69.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:56, Training Loss:8.532368891579765 Validation Loss: 1.2250833270576258 \n",
            " Training accuracy:78.13333129882812 Validation Accuracy: 65.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:57, Training Loss:8.0468674830028 Validation Loss: 1.3408519815189648 \n",
            " Training accuracy:79.33333587646484 Validation Accuracy: 67.60000610351562 \n",
            "--------------------------------\n",
            "Epoch:58, Training Loss:8.213667277778898 Validation Loss: 1.219663385231077 \n",
            " Training accuracy:78.44444274902344 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:59, Training Loss:7.692835346290043 Validation Loss: 1.4005352421563584 \n",
            " Training accuracy:79.73333740234375 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:60, Training Loss:7.645138531071799 Validation Loss: 1.4047968912273718 \n",
            " Training accuracy:80.35555267333984 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:61, Training Loss:7.7056122660636905 Validation Loss: 1.3438345586405667 \n",
            " Training accuracy:80.80000305175781 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:62, Training Loss:7.583494874409267 Validation Loss: 1.3706930720218915 \n",
            " Training accuracy:81.11111450195312 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:63, Training Loss:7.498494406257357 Validation Loss: 1.3988980451328097 \n",
            " Training accuracy:81.5999984741211 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:64, Training Loss:8.104254874161311 Validation Loss: 1.4740296378220428 \n",
            " Training accuracy:78.62222290039062 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:65, Training Loss:7.863818200145449 Validation Loss: 1.349898300816236 \n",
            " Training accuracy:81.02222442626953 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:66, Training Loss:7.052953057629722 Validation Loss: 1.4040061459853788 \n",
            " Training accuracy:83.11111450195312 Validation Accuracy: 66.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:67, Training Loss:7.046715184194701 Validation Loss: 1.3454357365014167 \n",
            " Training accuracy:82.8888931274414 Validation Accuracy: 66.0 \n",
            "--------------------------------\n",
            "Epoch:68, Training Loss:7.303912380763463 Validation Loss: 1.3841590086155666 \n",
            " Training accuracy:82.22222137451172 Validation Accuracy: 64.0 \n",
            "--------------------------------\n",
            "Epoch:69, Training Loss:7.049790062223162 Validation Loss: 1.4372229601559847 \n",
            " Training accuracy:81.9111099243164 Validation Accuracy: 65.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:70, Training Loss:7.148107522726059 Validation Loss: 1.4091667779240853 \n",
            " Training accuracy:83.46666717529297 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:71, Training Loss:7.359989409787314 Validation Loss: 1.5421188410571158 \n",
            " Training accuracy:82.5777816772461 Validation Accuracy: 59.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:72, Training Loss:7.215063496572631 Validation Loss: 1.5645861834140815 \n",
            " Training accuracy:82.31111145019531 Validation Accuracy: 59.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:73, Training Loss:6.4219992118222375 Validation Loss: 1.749507330251293 \n",
            " Training accuracy:84.84444427490234 Validation Accuracy: 58.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:74, Training Loss:6.920926795261247 Validation Loss: 1.5915895233591437 \n",
            " Training accuracy:83.77777862548828 Validation Accuracy: 62.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:75, Training Loss:6.473741694007601 Validation Loss: 1.617064657366093 \n",
            " Training accuracy:85.28888702392578 Validation Accuracy: 63.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:76, Training Loss:7.231344835247312 Validation Loss: 1.4659247865144398 \n",
            " Training accuracy:83.77777862548828 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:77, Training Loss:6.437387242487499 Validation Loss: 1.6049121547265277 \n",
            " Training accuracy:85.46666717529297 Validation Accuracy: 60.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:78, Training Loss:6.401038648826735 Validation Loss: 1.563884996990362 \n",
            " Training accuracy:85.33333587646484 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:79, Training Loss:6.969349664449692 Validation Loss: 1.6541127922054037 \n",
            " Training accuracy:83.55555725097656 Validation Accuracy: 56.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:80, Training Loss:6.721091087375369 Validation Loss: 1.5169481560258073 \n",
            " Training accuracy:84.62222290039062 Validation Accuracy: 59.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:81, Training Loss:6.51599169416087 Validation Loss: 1.541092676650048 \n",
            " Training accuracy:85.46666717529297 Validation Accuracy: 57.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:82, Training Loss:6.203197328107698 Validation Loss: 1.6504277294001486 \n",
            " Training accuracy:86.17778015136719 Validation Accuracy: 59.20000457763672 \n",
            "--------------------------------\n",
            "Epoch:83, Training Loss:5.690036175080708 Validation Loss: 1.6925492925225718 \n",
            " Training accuracy:87.9111099243164 Validation Accuracy: 58.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:84, Training Loss:5.9887874713965825 Validation Loss: 1.6612290795473745 \n",
            " Training accuracy:86.66666412353516 Validation Accuracy: 59.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:85, Training Loss:5.797331118157932 Validation Loss: 1.778601941782012 \n",
            " Training accuracy:86.93333435058594 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:86, Training Loss:5.891646838188171 Validation Loss: 1.8935134044196056 \n",
            " Training accuracy:86.5777816772461 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:87, Training Loss:5.952796898569379 Validation Loss: 1.8341812930185848 \n",
            " Training accuracy:87.24444580078125 Validation Accuracy: 58.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:88, Training Loss:5.809093222447804 Validation Loss: 1.793826824210425 \n",
            " Training accuracy:87.37777709960938 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:89, Training Loss:4.906863357339587 Validation Loss: 1.845294206042714 \n",
            " Training accuracy:90.04444885253906 Validation Accuracy: 62.400001525878906 \n",
            "--------------------------------\n",
            "Epoch:90, Training Loss:4.880236468144825 Validation Loss: 1.8047804262730995 \n",
            " Training accuracy:90.0 Validation Accuracy: 57.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:91, Training Loss:5.157485456977572 Validation Loss: 1.862548531866619 \n",
            " Training accuracy:89.20000457763672 Validation Accuracy: 60.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:92, Training Loss:4.467496636084148 Validation Loss: 1.930212148573793 \n",
            " Training accuracy:90.84444427490234 Validation Accuracy: 61.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:93, Training Loss:4.584395776901927 Validation Loss: 1.8021684248160195 \n",
            " Training accuracy:90.71111297607422 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:94, Training Loss:4.562195106489318 Validation Loss: 1.8186092000077583 \n",
            " Training accuracy:91.24444580078125 Validation Accuracy: 64.4000015258789 \n",
            "--------------------------------\n",
            "Epoch:95, Training Loss:4.423711898976139 Validation Loss: 2.0303322190892192 \n",
            " Training accuracy:90.93333435058594 Validation Accuracy: 62.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:96, Training Loss:4.281539174488612 Validation Loss: 2.2093730248684387 \n",
            " Training accuracy:90.62222290039062 Validation Accuracy: 64.80000305175781 \n",
            "--------------------------------\n",
            "Epoch:97, Training Loss:4.097803813644818 Validation Loss: 2.2570109553431394 \n",
            " Training accuracy:91.42222595214844 Validation Accuracy: 61.60000228881836 \n",
            "--------------------------------\n",
            "Epoch:98, Training Loss:3.696060776923384 Validation Loss: 2.199226738568307 \n",
            " Training accuracy:92.8888931274414 Validation Accuracy: 60.000003814697266 \n",
            "--------------------------------\n",
            "Epoch:99, Training Loss:4.148073565587401 Validation Loss: 2.114854374896477 \n",
            " Training accuracy:91.9111099243164 Validation Accuracy: 60.400001525878906 \n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "JC_nrAEPd0aQ",
        "outputId": "f7bc2e16-92b3-4986-b7dc-b45a7acd45f1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_list,'r',valid_loss_list , 'b')\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\"], loc =\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQcisxcEpaYB"
      },
      "source": [
        "def get_tensor_from_text_test(text,dataset):\n",
        "    word_list = []\n",
        "    train_word_to_index_dict = get_word_to_index(dataset['text'])\n",
        "    text = text.lower()\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word in train_word_to_index_dict.keys()]\n",
        "    for word in words:\n",
        "        word_list.append(train_word_to_index_dict[word])\n",
        "    if len(word_list) > TEXT_LENGTH:\n",
        "        word_list = word_list[:TEXT_LENGTH]\n",
        "    else:\n",
        "        word_list.extend([0]*(TEXT_LENGTH-len(word_list)))\n",
        "    \n",
        "    tensor_list = torch.tensor(word_list, device=device, dtype=torch.long)\n",
        "    return tensor_list\n",
        "\n",
        "class WeebitTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,test_dataset,train_dataset):\n",
        "        self.dataset = test_dataset\n",
        "        self.train_dataset = train_dataset \n",
        "    \n",
        "    def __getitem__(self,index): \n",
        "        text = self.dataset['text'].iloc[index]\n",
        "        x = get_tensor_from_text_test(text,self.train_dataset)\n",
        "        y = torch.tensor(self.dataset['readability'].iloc[index],dtype=torch.float,device=device)\n",
        "        return x,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def test(dataset):\n",
        "  testloader = torch.utils.data.DataLoader(\n",
        "                      dataset,\n",
        "                      batch_size=1)\n",
        "  with torch.no_grad():   \n",
        "    model = torch.load('/content/drive/MyDrive/Readability_Research_Paper/models/cnn_lstm/lstm_48.pkl')\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    target_list = []\n",
        "    output_list = []\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "      inputs, targets = data\n",
        "      # print(targets.item())\n",
        "      target_list.append(targets.item())\n",
        "      targets = torch.tensor(targets,dtype=torch.long,device=device)\n",
        "      outputs = model(inputs)\n",
        "      output_ids = torch.argmax(outputs, dim=1)\n",
        "      output_list.append(output_ids.item())\n",
        "      # outputs = outputs.squeeze(1)\n",
        "      test_correct += (output_ids == targets).float().sum()\n",
        "\n",
        "    test_accuracy = 100 * test_correct / len(dataset)\n",
        "    confusion_matrix_calc = confusion_matrix(target_list,output_list)\n",
        "    classification_report_calc = classification_report(target_list,output_list)\n",
        "    return test_accuracy, confusion_matrix_calc, classification_report_calc"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXngB7mm9G9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e61e585-5ddb-416f-c26e-c3a27465fa62"
      },
      "source": [
        "weebit_test_dataset = WeebitTestDataset(test_dataset, train_dataset)\n",
        "accuracy, confusion_matrix_calc, classification_report_calc = test(weebit_test_dataset)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIP5MhfG9XjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c53ccc3-30cf-4753-9cfd-93a8783414f5"
      },
      "source": [
        "print(\"Testing accuracy is: \" + str(accuracy.item()))\n",
        "print(\"\\nConfusion Matrix\")\n",
        "print(confusion_matrix_calc)\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report_calc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy is: 64.0\n",
            "\n",
            "Confusion Matrix\n",
            "[[50 41  4  5  0]\n",
            " [16 63 20  1  0]\n",
            " [ 8 48 43  1  0]\n",
            " [ 7  0  0 89  4]\n",
            " [ 2  0  4 19 75]]\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.50      0.55       100\n",
            "         1.0       0.41      0.63      0.50       100\n",
            "         2.0       0.61      0.43      0.50       100\n",
            "         3.0       0.77      0.89      0.83       100\n",
            "         4.0       0.95      0.75      0.84       100\n",
            "\n",
            "    accuracy                           0.64       500\n",
            "   macro avg       0.67      0.64      0.64       500\n",
            "weighted avg       0.67      0.64      0.64       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtl34zWrN6Lz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}